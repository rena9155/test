{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e52629",
   "metadata": {
    "id": "08e52629"
   },
   "source": [
    "# Descriptive Statistics - A Brief Introduction\n",
    "\n",
    "The statistics prework material introduces incoming students to the most important **statistical concepts** required in data science. We encourage you to get familiar with these concepts before the first day of the bootcamp because they form the foundation of your understanding about how to find structure in, or give deeper insight, into data.\n",
    "\n",
    "\n",
    "The material is delivered in a tutorial format where short exercises are integrated into the notebook so that you are able to practice as you are learning. Please complete all the sections marked 'Exercise' to the best of your ability.\n",
    "\n",
    "\n",
    "In this tutorial notebook we will begin with the elements of **Descriptive Statistics** and their applications in Python in this notebook. So what is Descriptive Statistics?\n",
    "\n",
    "\n",
    "Descriptive statistics consist of methods for organizing and summarizing information (Weiss, 1999). This is in contrast to statistical inference, where predictions and generalizations are made about phenomena represented by the data. So the data at hand are described, but no conclusions that could be applied to a broader population are drawn.\n",
    "\n",
    "This can be done through visualizations (graphs, charts, tables, plots..) or calculating various descriptive measures such as mean, variance and quantiles. Descriptive statistics can help with choosing appropriate inferential methods.\n",
    "\n",
    "\n",
    "\n",
    "## Important Concepts Covered in this Notebook\n",
    "  - [Population vs sample](#Population-vs-Sample)\n",
    "  - [Data types](#Data-Types)  \n",
    "  - [Histograms](#Histogram)\n",
    "  - [Probability distributions I](#Probability-Distributions---I)\n",
    "  - [Central tendencies](#Central-Tendencies)\n",
    "  - [Variance, standard Deviation](#Measures-of-Spread)\n",
    "  - [Skewness](#Skewness)\n",
    "  - [Probability distributions II](#Probability-Distributions---II)\n",
    "  - [Gaussian (Normal) distribution](#Gaussian-(normal)-Distribution)\n",
    "  - [Multivariate Gaussian Distribution](#Multivariate-Gaussian-Distribution)\n",
    "  - [Outliers, IQR, Boxplots and Violin Plots](#Outliers,-IQR,-Boxplots-and-Violin-Plots)\n",
    "\n",
    "\n",
    "\n",
    "## Links to Extra Materials\n",
    "  - Textbook: [Practical Statistics for Data Scientists](https://www.oreilly.com/library/view/practical-statistics-for/9781492072935/)\n",
    "\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "We have prepared examples on the most fundamental concepts. Some of them also include a short exercise to give you the opportunity to practice the concept you have just learned.\n",
    "\n",
    "<span style=\"color: red;\"> **The exercises are annotated as follows:** </span>\n",
    "\n",
    "text of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f925a70",
   "metadata": {
    "id": "3f925a70"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c37e83",
   "metadata": {
    "id": "c9c37e83"
   },
   "source": [
    "# Population vs Sample\n",
    "\n",
    "There is an important distinction to be made between a sample and a popualtion:\n",
    "\n",
    "• **Population**: Group that the researcher wishes to study.\n",
    "  It represents the target of an investigation (goal for inferential statistics).\n",
    "\n",
    "• **Sample**: A group of individuals selected from the population.\n",
    "  Descriptive Statistics describes the sample (observed data).\n",
    "\n",
    "\n",
    "Often, it is not possible to study the whole population of interest, so samples are drawn from it and investigated. Later, conclusions from the sample can be extrapolated to the population by inferential statistics. For example, a survey is completed by 2000 people about their pets to determine the number of pets in Swiss households. This is obviously only a small sample of the whole Swiss population. Or if the efficacy of a new drug is tested, this is usually done in controlled clinical trials, where only a fraction of patients with the disease are included.\n",
    "\n",
    "\n",
    "It can happen that we have access to the whole population. It happens in certain cases, where we have a very narrow research question. For example, if a teacher wants to determine the students' final exam scores in math for the last year, she has access to all the data and can consider the population data.\n",
    "\n",
    "**Big part of data science is about drawing conclusions about popualtion, while knowing only sample.**\n",
    "\n",
    "Below is a representation of the concept of population (left side) vs. sample (right side).\n",
    "\n",
    "![](https://i.imgur.com/Bxg6rcL.png)\n",
    "\n",
    "\n",
    "\n",
    "#  Data Types\n",
    "\n",
    "Understanding data types is important because some statistical methods can only be used with certain data types.\n",
    "For example, analysing continuous data using a method that is only meaningful for categorical data, would result in an incorrect analysis.\n",
    "\n",
    "Therefore, knowing the type of data you are dealing with is a crucial prerequisite for doing exploratory data analysis.\n",
    "\n",
    "Data can be categorized into the following:\n",
    "\n",
    "* Categorical Data (Qualitative Data)\n",
    "  + Nominal Data: “labels” = no quantitative value, have no order\n",
    "\t\tExample: \t\tfemale, male\n",
    "\n",
    "  + Ordinal Data: “labels” = no quantitative value, order is important\n",
    "\t\tExample: \t\tgood > intermediate > bad\n",
    "\n",
    "* Numerical Data (Quantitative Data)\n",
    "  +  Discrete Data: can only take on certain values\n",
    "\t\tExample: \t\tcounts of coin flip: 1,2,3... (but not 3.5)\n",
    "\n",
    "  + Continuous Data: can take on every value\n",
    "\t\tExample: \t\tweight: 0.3, 38, 47.3, 98 [kg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2149f07",
   "metadata": {
    "id": "b2149f07"
   },
   "source": [
    "![](https://i.imgur.com/VXTY4k6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c753032",
   "metadata": {
    "id": "1c753032"
   },
   "source": [
    "# Histogram \n",
    "\n",
    "Histograms provide a visual interpretation of numerical data by indicating the number of data points that lie within a range of values. The higher that the bar is, the greater the frequency of data values in that bin.\n",
    "\n",
    "\n",
    "## Frequency Histogram  \n",
    "\n",
    "A regular histogram is a frequency histogram. It has frequency (counts) on the y-axis.    \n",
    "\n",
    "To demonstrate how to plot a frequency histogram in python, we will use the `seaborn` library which makes things easier and more concise.\n",
    "\n",
    "The `histplot()` function in python allows us to compute a histogram using the data values provided  \n",
    "\n",
    "We will make use of the built-in Iris dataset which has information about different types of Iris flowers. Let's start by loading our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f1edd",
   "metadata": {
    "id": "1a8f1edd"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1db3e",
   "metadata": {
    "id": "fee1db3e"
   },
   "source": [
    "The histogram representing the Sepal Length from the iris dataset can be seen below. \n",
    "\n",
    "The x-axis represents the sepal length, and the y-axis represents the raw frequency (a count of the number of times that sepal length occurs in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768dde9",
   "metadata": {
    "id": "4768dde9"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x='sepal_length', data=iris);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02ba18",
   "metadata": {
    "id": "2f02ba18"
   },
   "source": [
    "## Relative Frequency Histogram\n",
    "\n",
    "A relative frequency histogram shows the frequency (counts) as percentages. This means that the y-axis represents probability densities and the histogram has a total area of one. \n",
    "\n",
    "Using the same Sepal Length data as in the frequency histogram above, we will plot a relative frequency histogram.  \n",
    "The x-axis represents the sepal length, and the y-axis represents the **relative frequency** (a percentage of the whole).    \n",
    "\n",
    "This histogram may lead you to wonder, can we compute some parameters from this data?\n",
    "(This will be the goal of the following sections, where you will see that there are many other ways of representing the data in a plot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905da4a",
   "metadata": {
    "id": "a905da4a"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x='sepal_length', data=iris, stat='density');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66805496",
   "metadata": {
    "id": "66805496"
   },
   "source": [
    "There are a variety of ways to visualize the density plot and we show a couple of them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965fcc5",
   "metadata": {
    "id": "5965fcc5"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x='sepal_length', data=iris, kde=True, stat='density');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a3cce",
   "metadata": {
    "id": "eb8a3cce"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(x='sepal_length', data=iris, shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39b56a",
   "metadata": {
    "id": "9c39b56a"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the distribution (histogram and density plots) for iris sepal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f510526",
   "metadata": {
    "id": "3f510526"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5285c",
   "metadata": {
    "id": "b4f5285c"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51552b03",
   "metadata": {
    "id": "51552b03"
   },
   "source": [
    "# Probability Distributions - I\n",
    "\n",
    "A probability distribution is a function that describes the likelihood that your variable will obtain specific values.\n",
    "\n",
    "The two main functions are:\n",
    "\n",
    "* Probability Mass Function (for discrete variables)\n",
    "* Probability Density Function (for continuous variables)\n",
    "\n",
    "A distribution has parameters describing its shape.\n",
    "There are many different classifications of probability distributions. Some of them are described in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec1442",
   "metadata": {
    "id": "88ec1442"
   },
   "source": [
    "## Probability Mass Function (PMF):\n",
    "\n",
    "Probability mass function is used for discrete random variables. It provides the probability of occurence for each value of the random variable.\n",
    "The values of PMF always sum up to 1.\n",
    "\n",
    "- Probability is the frequency expressed in fraction of the sample size ’n’. In order to derive probabilities from frequency, you divide the frequencies with ’n’. This process is called normalization.\n",
    "\n",
    "- Probability mass function (PMF) maps each value to its corresponding probability. PMF is plotted for discrete distributions. For continuous distributions, we have PDF or Probability Density Function, which we will look at later.\n",
    "\n",
    "![](https://i.imgur.com/I78dFDS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836268b",
   "metadata": {
    "id": "6836268b"
   },
   "source": [
    "## PMF - Scenario: Dice Rolls\n",
    "\n",
    "Let's assume a fair die is rolled several times with the following outcomes:\n",
    "\n",
    "```\n",
    "outcomes = [1, 2, 1, 1, 4, 5 ,6 ,6, 5, 5, 3, 3, 2, 1]\n",
    "```\n",
    "\n",
    "Can we plot the PMF for the above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115db124",
   "metadata": {
    "id": "115db124"
   },
   "source": [
    "Let’s take an even simpler example first.\n",
    "\n",
    "Assume one roll of each value for an unbiased die. \n",
    "\n",
    "The sample-set will look something like this : `[1,2,3,4,5,6]` \n",
    "\n",
    "The probability of each of the numbers appearing will be 1/6 or 0.167. \n",
    "\n",
    "This is a uniform distribution since the probabilities of all the values in the sample are the same.\n",
    "\n",
    "So the PMF will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b279a5f",
   "metadata": {
    "id": "7b279a5f"
   },
   "outputs": [],
   "source": [
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df = pd.DataFrame(outcomes, columns=['DieRoll'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af41cc",
   "metadata": {
    "id": "11af41cc"
   },
   "outputs": [],
   "source": [
    "pmf = df['DieRoll'].value_counts(normalize=True)\n",
    "pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82401b2",
   "metadata": {
    "id": "b82401b2"
   },
   "outputs": [],
   "source": [
    "pmf.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b8364",
   "metadata": {
    "id": "1f5b8364"
   },
   "source": [
    "Can we now try and compute the PMF of our previous event:\n",
    "    \n",
    "```    \n",
    "outcomes = [1, 2, 1, 1, 4, 5 ,6 ,6, 5, 5, 3, 3, 2, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ecd33",
   "metadata": {
    "id": "546ecd33"
   },
   "outputs": [],
   "source": [
    "outcomes = [1, 2, 1, 1, 4, 5 ,6 ,6, 5, 5, 3, 3, 2, 1]\n",
    "\n",
    "df = pd.DataFrame(outcomes, columns=['DieRoll'])\n",
    "pmf = df['DieRoll'].value_counts(normalize=True)\n",
    "pmf.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc811274",
   "metadata": {
    "id": "cc811274"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the PMF for the following outcomes of a 12 sided die!\n",
    "\n",
    "```\n",
    "outcomes = [11, 2, 5, 5, 12, 12 ,7 ,6, 7, 7, 2, 3, 2, 11]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8bbed",
   "metadata": {
    "id": "c1c8bbed"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "outcomes = [11, 2, 5, 5, 12, 12 ,7 ,6, 7, 7, 2, 3, 2, 11]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6173b5d",
   "metadata": {
    "id": "a6173b5d"
   },
   "source": [
    "## Probability Density Function (PDF):\n",
    "\n",
    "Probability density function is used for continuous random variables.\n",
    "\n",
    "- By definition Probability Density of x is the measure of probability per unit of x.\n",
    "\n",
    "- In a PMF if pick a value say 1 (in the example of a die roll) and try to find its corresponding probability of occurring then we can easily find its probability to be 0.167. However, in a PDF it is not that simple.\n",
    "\n",
    "- In the case of PDF we find the probability of x lying within a certain range of values, any single point will have a probability density of zero and the reason being:\n",
    "    - PDF is calculated as the area under the graph and in general, area is calculated by multiplying length and height. \n",
    "    - Any single point will have a length of zero. \n",
    "    - However, if we consider a range or collection of many single points we can find its corresponding probability density to be non-zero.\n",
    "\n",
    "The point on the red curve ($p(x)$) represents probabaility of random variable being equal to $x$.\n",
    "The grey area represents the probability of a continuous random variable falling between, or being exactly equal to, $a$ and $b$.\n",
    "\n",
    "The area under PDF (or mathematically, its infinite integral) is always equal to 1.\n",
    "\n",
    "![](https://i.imgur.com/z2S5hl0.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2b287",
   "metadata": {
    "id": "0eb2b287"
   },
   "source": [
    "## PDF - Scenario: Exam Scores\n",
    "\n",
    "Let's assume we record students' scores in an exam with the following scores:\n",
    "\n",
    "```\n",
    "outcomes = [2.5, 9.5, 1.1, 4.3, 2.5, 7.8, 6.7, 8.2, 9.1, 7.7, 4.5, 3.3, 6.7, 6.5, 6.2]\n",
    "```\n",
    "\n",
    "Can we plot the PDF for the above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82cead",
   "metadata": {
    "id": "cb82cead"
   },
   "outputs": [],
   "source": [
    "scores = [2.5, 9.5, 1.1, 4.3, 2.5, 7.8, 6.7, 8.2, 9.1, 7.7, 4.5, 3.3, 6.7, 6.5, 6.2]\n",
    "\n",
    "df = pd.DataFrame(scores, columns=['Score'])\n",
    "\n",
    "sns.histplot(x='Score', data=df, kde=True, cumulative=False, stat='probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff74a0e",
   "metadata": {
    "id": "fff74a0e"
   },
   "source": [
    "## Cumulative Distribution Function (CDF):\n",
    "\n",
    "Cumulative distribution function describes what percentage of the data in this distribution falls below a certain value. \n",
    "\n",
    "CDF(x) is the probability that a random value ‘X’ will be less than or equal to x or CDF(x) implies the fraction of values that are lesser than or equal to x.\n",
    "\n",
    "It can be calculated for both discrete and continuous random variables. /\n",
    "\n",
    "For continuous variables it can be interpreted as the area under the PDF curve until a certain point. /\n",
    "\n",
    "For discrete variables it is the sum of the values of PMF until a certain point. /\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/FI8hsRo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f23dc0",
   "metadata": {
    "id": "26f23dc0"
   },
   "source": [
    "## CDF - Scenario: Exam Scores\n",
    "\n",
    "Let's assume we record students' scores in an exam with the following scores:\n",
    "\n",
    "```\n",
    "outcomes = [2.5, 9.5, 1.1, 4.3, 2.5, 7.8, 6.7, 8.2, 9.1, 7.7, 4.5, 3.3, 6.7, 6.5, 6.2]\n",
    "```\n",
    "\n",
    "Can we plot the CDF for the above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e749dd",
   "metadata": {
    "id": "13e749dd"
   },
   "outputs": [],
   "source": [
    "scores = [2.5, 9.5, 1.1, 4.3, 2.5, 7.8, 6.7, 8.2, 9.1, 7.7, 4.5, 3.3, 6.7, 6.5, 6.2]\n",
    "\n",
    "df = pd.DataFrame(scores, columns=['Score'])\n",
    "\n",
    "sns.histplot(x='Score', data=df, kde=True, cumulative=True, stat='probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacfa89",
   "metadata": {
    "id": "0cacfa89"
   },
   "source": [
    "We could also use the `displot()` function to get the actual CDF curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3415a",
   "metadata": {
    "id": "a1c3415a"
   },
   "outputs": [],
   "source": [
    "sns.displot(x='Score', data=df, kind='ecdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7c992",
   "metadata": {
    "id": "3df7c992"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the CDF for petal length from the IRIS dataset used earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da423ae6",
   "metadata": {
    "id": "da423ae6"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d9423",
   "metadata": {
    "id": "711d9423"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e87a8",
   "metadata": {
    "id": "b73e87a8"
   },
   "source": [
    "# Central Tendencies\n",
    "\n",
    "One of the most important measures of descriptive statistics are the central tendencies.\n",
    "These indicate the most typical value for a collected set of measurements.\n",
    "\n",
    "It is a single value that attempts to describe all variables in the data.\n",
    "\n",
    "There are three measures for central tendencies:\n",
    "\n",
    "* (Arithmetic) Mean\n",
    "* Median\n",
    "* Mode\n",
    "\n",
    "The colloquial *average* can refer to any of those tendencies.\n",
    "\n",
    "\n",
    "**Mean**: \n",
    "\n",
    "The mean is the sum of all the values in a set, divided by the number of values.\n",
    "$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_{i}$$\n",
    "where $x_{i}$ is observation $i$, and $n$ is number of values in a set.\n",
    "\n",
    "\n",
    "\n",
    "**Median**: \n",
    "\n",
    "The median is the value of the variable in the dataset that divides the set of observed values in half. To obtain the median: \n",
    "\n",
    "1. Arrange the observed values in increasing order \n",
    "2. Determine the sample median: \n",
    "    a. Odd number of observations: median is the value in the middle \n",
    "    b. Even number of observations: number halfway between the two values in the middle. \n",
    "\n",
    "\n",
    "\n",
    "**Mode**: \n",
    "\n",
    "The mode is the value that has the highest number of occurrences in a set of data. Unlike the mean and median, the mode can be computed for both numeric and categorical data.\n",
    "\n",
    "Depending on the distribution, the mean, median and mode can be the same (normal distribution) or all different (skewed distributions). \n",
    "\n",
    "In the image below this point becomes clearer, normal distributions and skewness will be introduced in the chapters below.\n",
    "\n",
    "![](https://i.imgur.com/bPUXrSE.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0e54a",
   "metadata": {
    "id": "7ba0e54a"
   },
   "source": [
    "## Example\n",
    "\n",
    "To demonstrate how the mean and median can differ greatly as a result of the skewed dataset, we will calculate these values for two different datasets.   \n",
    "\n",
    "We simulate a symmetric distribution of 1000 data points using a mean of 5.    \n",
    "We can see from the frequency histogram that it is indeed a symmetric distribution.     \n",
    "Then calculate the mean and median of our simulated data. These two values are almost identical.      \n",
    "\n",
    "We also simulate a skewed distribution of 1000 data points using a mean of 5.    \n",
    "We can see from the frequency histogram that is is indeed a skewed distribution.    \n",
    "When we calculate the mean and median of our simulated data, these two values have a greater difference than for the symmetric distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff194f",
   "metadata": {
    "id": "22ff194f"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "#symmetric distribuion\n",
    "mean = 5\n",
    "std=1\n",
    "symmetric_distribution_values = norm.rvs(loc=mean, scale=std, size=1000, random_state=0)\n",
    "\n",
    "sns.histplot(symmetric_distribution_values, bins=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb66695",
   "metadata": {
    "id": "dfb66695"
   },
   "source": [
    "We can compute the central tendency measures as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d9b9b",
   "metadata": {
    "id": "668d9b9b"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0119a3c",
   "metadata": {
    "id": "d0119a3c"
   },
   "outputs": [],
   "source": [
    "print('Mean:', np.mean(symmetric_distribution_values))\n",
    "print('Median:', np.median(symmetric_distribution_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d57d1",
   "metadata": {
    "id": "180d57d1"
   },
   "source": [
    "`skewnorm()` takes a real number  as a skewness parameter.\n",
    "\n",
    "When: \n",
    "\n",
    "- a = 0 the distribution is identical to a normal distribution (norm)\n",
    "- a > 0 the distribution is right skewed (positive skew)\n",
    "- a < 0 the distribution is left skewed (negative skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42486e1b",
   "metadata": {
    "id": "42486e1b"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "\n",
    "# right-skewed distribution\n",
    "mean = 5\n",
    "std=1\n",
    "skewness=5\n",
    "right_skewed_distribution_values = skewnorm.rvs(a=skewness, loc=mean, scale=std, \n",
    "                                          size=1000, random_state=0)\n",
    "\n",
    "sns.histplot(right_skewed_distribution_values, bins=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ee7b6",
   "metadata": {
    "id": "eb9ee7b6"
   },
   "outputs": [],
   "source": [
    "print('Mean:', np.mean(right_skewed_distribution_values))\n",
    "print('Median:', np.median(right_skewed_distribution_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4caf2c0",
   "metadata": {
    "id": "b4caf2c0"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Create a left-skewed (negative skew) distribution with skewness of -5 and mean of 5 and std deviation of 1 and a 1000 samples similar to the previous distribution.\n",
    "\n",
    "Plot the histogram. \n",
    "Compute the mean and median and comment on any special observations if you notice anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb68895",
   "metadata": {
    "id": "9eb68895"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# right-skewed distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46d858",
   "metadata": {
    "id": "7d46d858"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aab793",
   "metadata": {
    "id": "00aab793"
   },
   "source": [
    "As expected the median is greater than mean for left-skewed distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4718979",
   "metadata": {
    "id": "c4718979"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Using the motor trends cars dataset (these data give the mpg(determinant of fuel efficiency) of cars), calculate the mean, median and mode of `mpg`. \n",
    "\n",
    "Also plot the histogram of these data.\n",
    "\n",
    "\n",
    "Hint: the mode is not a built-in function in `numpy`. You can either write the function yourself or find it from the `statistics` package in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac30ede",
   "metadata": {
    "id": "3ac30ede"
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv('data/pw_stats_02_mtcars.csv')\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf9385",
   "metadata": {
    "id": "f2bf9385"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bee52d",
   "metadata": {
    "id": "b9bee52d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9492a74",
   "metadata": {
    "id": "c9492a74"
   },
   "source": [
    "# Measures of Spread\n",
    "\n",
    "\n",
    "## Variance\n",
    "\n",
    "\n",
    "The variance is a measure of how spread out a distribution is. The larger the variance, the further spread out the data. A small variance indicates that the data points tend to be very close to the mean (expected value). A high variance indicates that the data points are very spread out from the mean and from each other.\n",
    "\n",
    "![](https://i.imgur.com/Htvs6LI.png)\n",
    "\n",
    "\n",
    "\n",
    "It is the average squared deviation of the observations from their mean. It is a mathematical way to describe how the observations “vary” from the mean.\n",
    "\n",
    "\n",
    "The formula for the sample variance is:\n",
    "\n",
    "$$s^{2} = \\frac{\\sum_{i=1}^{n}\n",
    "  \\left(x_{i} - \\bar{x}\\right)^{2}}\n",
    "  {n-1}$$\n",
    "  \n",
    "where $x_{i}$ is observation $i$, and $n$ is number of values in a set.\n",
    "\n",
    "Why do we square the deviations?\n",
    "\n",
    "To calculate variance, the mean of a group of scores is subtracted from each score to give a group of “deviations”.\n",
    "\n",
    "However, positive and negative scores cancel each other out. If you first square the deviation scores and then add them, you avoid this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d81c0",
   "metadata": {
    "id": "ad4d81c0"
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "Compute the sample variance of the displacement `disp` column in the cars dataset.\n",
    "\n",
    "Hint: There should be a function in `numpy` to compute the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258925c",
   "metadata": {
    "id": "5258925c"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdad91a",
   "metadata": {
    "id": "0bdad91a"
   },
   "source": [
    "Compute the sample variance of the horsepower `hp` column in the cars dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2537441",
   "metadata": {
    "id": "a2537441"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95d5e3",
   "metadata": {
    "id": "9f95d5e3"
   },
   "source": [
    "__Explain the difference in your results:__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e59b95",
   "metadata": {
    "id": "e2e59b95"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d784a",
   "metadata": {
    "id": "416d784a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ff7b61",
   "metadata": {
    "id": "51ff7b61"
   },
   "source": [
    "## Standard Deviation\n",
    "\n",
    "The square root of the variance is the standard deviation. \n",
    "\n",
    "The variance is hard to interpret as it's unit is the square of the unit of the variable. \n",
    "\n",
    "To get back the original unit, you can take the square root of the variance, which is the standard deviation. Below is the formula for the sample standard deviation.\n",
    "\n",
    "$$s = \\sqrt{\\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1}}$$\n",
    "\n",
    "where $x_{i}$ is observation $i$, and $n$ is number of values in a set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62070f1",
   "metadata": {
    "id": "f62070f1"
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "Compute the sample standard deviation of the `mpg` column in the cars dataset. You can either take the square-root of the variance calculated above, or use directly a function from `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b795a9f",
   "metadata": {
    "id": "3b795a9f"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e7446f",
   "metadata": {
    "id": "20e7446f"
   },
   "source": [
    "## Population and Sample\n",
    "\n",
    "There are two different types of standard deviations (and variances):\n",
    "\n",
    "* population standard deviation\n",
    "$$\\sigma= \\sqrt{\\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\mu{}\\right)^{2}} {n}}$$\n",
    "* sample standard deviation\n",
    "$$\\sigma= \\sqrt{\\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\mu{}\\right)^{2}} {n-1}}$$\n",
    "\n",
    "where $x_{i}$ is observation $i$, and $n$ is number of values in a set.\n",
    "\n",
    "The population standard deviation is used when the whole population is investigated. \n",
    "\n",
    "The sample standard deviation is used when you work with  entire population sample.\n",
    "\n",
    "When working with sample, rather than population, we are likely to underestimate the true population variance. We don't have all possible data available, and it is likely that some extreme observations are missing.\n",
    "\n",
    "To correct for it, we divide the sum of deviations by $n-1$ instead of $n$. \n",
    "\n",
    "This means that sample standard deviation will be slightly higher than population one.\n",
    "\n",
    "Sample standard deviation is called an 'unbiased estimator'. \n",
    "\n",
    "Applying population sd to the sample data would result in a biased estimate.\n",
    "\n",
    "\n",
    "**By default, all statistical libraries use sample standard deviation.**\n",
    "\n",
    "Wonder why we correct for bias in this way? Check the proof [here](https://www.youtube.com/watch/D1hgiAla3KI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f615c6f",
   "metadata": {
    "id": "8f615c6f"
   },
   "source": [
    "## Skewness\n",
    "\n",
    "\n",
    "Another important measure to describe a dataset is the skewness. Intuitively, the skewness is a measure of symmetry. \n",
    "\n",
    "As a rule, negative skewness indicates that the mean of the data values is less than the median, and the data distribution is left-skewed (the distribution has a long tail in the negative direction or to the left.) \n",
    "\n",
    "Positive skewness would indicate that the mean of the data values is larger than the median, and the data distribution is right-skewed (the distribution has a long tail in the positive direction or to the right.)\n",
    "\n",
    "This can be seen in the picture below.\n",
    "\n",
    "![](https://i.imgur.com/bPUXrSE.png)\n",
    "\n",
    "\n",
    "The formula to calculate the skewness is given as: $$g_1=\\frac{m_3}{m_2^{3/2}}$$\n",
    "\n",
    "where $m$ are the sample moments, defined as: $$ m_r = \\sum\\limits_{i=1}^{n} (x_i - \\mu)^r / n $$\n",
    "\n",
    "where $r$ is the moment order, $n$ is number of observations, and $x_{i}$ is an observation value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b73f4e",
   "metadata": {
    "id": "93b73f4e"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the histogram and compute the skewness of `hp` in the dataset cars.\n",
    "\n",
    "Hint:\n",
    "The easiest way of getting a visual overview of the data is by plotting the histogram with seaborn as we showed earlier.\n",
    "\n",
    "Therefore, first plot the data to get this visual intuition and maybe already predict if the data is skewed to the left or right. \n",
    "\n",
    "Afterwards, confirm your prediction by calculating the skewness coefficient. We apply the function [__`skew()`__](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html) from `scipy.stats` \n",
    "\n",
    "If the coefficient is negative, that means that the data is left-skewed, if the coefficient is positive it is right-skewed and if it's 0, the data is not skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f843e4",
   "metadata": {
    "id": "99f843e4"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "sns.histplot(x='hp', data=cars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9c0f0",
   "metadata": {
    "id": "81d9c0f0"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "from scipy.stats import skew\n",
    "\n",
    "skew(cars['hp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a23cd",
   "metadata": {
    "id": "557a23cd"
   },
   "source": [
    "__Conclusion:__\n",
    "\n",
    "The skewness of `hp` is 0.76. It indicates that the data is skewed to the right. This can also be seen in the histogram above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa177b8",
   "metadata": {
    "id": "ffa177b8"
   },
   "source": [
    "# Probability Distributions - II \n",
    "\n",
    "A distribution has parameters describing its shape. There are many different classifications of probability distributions. Some of them are described in more detail below, such as the normal distribution, binomial distribution, and Poisson distribution. \n",
    "\n",
    "The different probability distributions serve different purposes and represent different data generation processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63419ac1",
   "metadata": {
    "id": "63419ac1"
   },
   "source": [
    "## Gaussian (normal) Distribution \n",
    "\n",
    "In a Gaussian or normal distribution, the mean, median and mode are the same, the curve is symmetric around the mean and exactly half of the values are to the left and the other half to the right of the center. \n",
    "\n",
    "Examples for normally distributed data are the height of people, measurement errors, blood pressure, IQ scores, salaries or points in an exam.\n",
    "\n",
    "The normal distribution is defined by two parameters: the mean and the variance or standard deviation.\n",
    "\n",
    "The standard normal distribution is a special case of a normal distribution with mean of 0 and standard deviation of 1. \n",
    "\n",
    "Any Gaussian can be represented as a linear sum of standard normal distributions.\n",
    "\n",
    "We will have a closer look at normal distributions and the applications of the concepts above in the following sections.\n",
    "\n",
    "\n",
    "\n",
    "## Random data generation from a normal distribution: \n",
    "\n",
    "`scipy.stats` has a `norm.rvs()` function that you can use to generate a vector of normally distributed random numbers.\n",
    "\n",
    "To check the parameters, you can always refer to the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)\n",
    "\n",
    "Here is some usage of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd60b4",
   "metadata": {
    "id": "a7fd60b4"
   },
   "outputs": [],
   "source": [
    "# Following code generates random samples of different sizes from a normal distribution.\n",
    "mean=170\n",
    "std=10\n",
    "n1 = norm.rvs(loc=mean, scale=std, size=10)\n",
    "\n",
    "n2 = norm.rvs(loc=mean, scale=std, size=100)\n",
    "\n",
    "n3 = norm.rvs(loc=mean, scale=std, size=1000)\n",
    "\n",
    "# Let's look at one\n",
    "n1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090209a3",
   "metadata": {
    "id": "090209a3"
   },
   "source": [
    "## Set seed to generate reproducible random sample\n",
    "\n",
    "You can set a seed or random_state so that your code is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220061c",
   "metadata": {
    "id": "a220061c"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "norm.rvs(loc=mean, scale=std, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f6314f",
   "metadata": {
    "id": "b9f6314f"
   },
   "source": [
    "If we set the seed to the same number, it will generate the same vector. We can also do it using random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c267c",
   "metadata": {
    "id": "bd4c267c"
   },
   "outputs": [],
   "source": [
    "norm.rvs(loc=mean, scale=std, size=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f0280",
   "metadata": {
    "id": "780f0280"
   },
   "source": [
    "Without seed after each run you get different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc571a",
   "metadata": {
    "id": "41bc571a"
   },
   "outputs": [],
   "source": [
    "norm.rvs(loc=mean, scale=std, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffeed74",
   "metadata": {
    "id": "8ffeed74"
   },
   "source": [
    "Let's plot the distributions of the three samples we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f7ac0",
   "metadata": {
    "id": "e58f7ac0"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "sns.histplot(n1, ax=ax[0])\n",
    "sns.histplot(n2, ax=ax[1])\n",
    "sns.histplot(n3, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d4e9e",
   "metadata": {
    "id": "989d4e9e"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the 3 distributions, n1, n2 and n3 from above using density plots in seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807de94f",
   "metadata": {
    "id": "807de94f"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6576b7",
   "metadata": {
    "id": "6a6576b7"
   },
   "source": [
    "**Which histogram is most centered around the true mean of 170?**\n",
    "The one with the biggest sample size.\n",
    "\n",
    "**What conclusion can we draw from this?**\n",
    "As sample size increases, our sample mean becomes closer and closer to the real mean "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863f45d",
   "metadata": {
    "id": "0863f45d"
   },
   "source": [
    "## Properties of Gaussians\n",
    "\n",
    "The sum of two gaussians is a gaussian.   \n",
    "\n",
    "This means that if $X \\sim N(\\mu_x,\\sigma_x)$ and $Y \\sim N(\\mu_y,\\sigma_y)$   \n",
    "\n",
    "and $Z = X + Y$    \n",
    "then $Z \\sim N(\\mu_x + \\mu_y,  \\sqrt{\\sigma_x^2 + \\sigma_y^2})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296a473",
   "metadata": {
    "id": "8296a473"
   },
   "outputs": [],
   "source": [
    "##  normal with mean 10 and std as 2\n",
    "x = norm.rvs(loc=10, scale=2, size=10000, random_state=42)\n",
    "## normal dist with mean 20 and std as 4\n",
    "y = norm.rvs(loc=20, scale=4, size=10000, random_state=42)\n",
    "\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa9340",
   "metadata": {
    "id": "7caa9340"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "sns.kdeplot(x, ax=ax[0], shade=True)\n",
    "sns.kdeplot(y, ax=ax[1], shade=True)\n",
    "sns.kdeplot(z, ax=ax[2], shade=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824ec59",
   "metadata": {
    "id": "3824ec59"
   },
   "outputs": [],
   "source": [
    "np.mean(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a7f50",
   "metadata": {
    "id": "b73a7f50"
   },
   "outputs": [],
   "source": [
    "np.std(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a12a4",
   "metadata": {
    "id": "ed1a12a4"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "How increasing or decreasing the sample size in the code above (10,20,100,1000,10000, 100000) impacts the mean and standard deviation of $Z$?\n",
    "\n",
    "Hint:\n",
    "\n",
    "- run a loop for each sample size\n",
    "- generate x and y using `norm.rvs()`\n",
    "- z = x + y\n",
    "- store sample size, mean and standard deviation of Z\n",
    "- display results as a dataframe or any other convenient structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571cb3a",
   "metadata": {
    "id": "d571cb3a"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "n = [10,20,100,1000,10000, 100000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for sample_size in n:\n",
    "    <FILL CODE HERE>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3dcaa",
   "metadata": {
    "id": "58b3dcaa"
   },
   "source": [
    "## The probability density function: \n",
    "\n",
    "The normal distribution has density $$f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{1}{2} (\\frac{x-\\mu}{\\sigma})^2}$$ \n",
    "\n",
    "where $\\mu$ is the mean of the distribution and $\\sigma$ the standard deviation. \n",
    "\n",
    "X is the value for which we want to calculate the probability.\n",
    "\n",
    "As we see, the density function requires three inputs x, $\\mu$ , and $\\sigma$. \n",
    "\n",
    "The following command gives density for a data point x = 0 with $\\mu$ = 0 and $\\sigma$ = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94c341",
   "metadata": {
    "id": "5e94c341"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.pdf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f67097",
   "metadata": {
    "id": "90f67097"
   },
   "outputs": [],
   "source": [
    "norm.pdf(0, loc=0, scale=1) #same as norm.pdf(0), as mean = 0, std = 1 are default parameters\n",
    "# always remember loc = mean and scale = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c6723",
   "metadata": {
    "id": "773c6723"
   },
   "outputs": [],
   "source": [
    "## what happens when mean is farther from x\n",
    "norm.pdf(0, loc=10, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5c5b7",
   "metadata": {
    "id": "aac5c5b7"
   },
   "source": [
    "`norm.pdf()` is also used as a **likelihood function** for normal distributions. \n",
    "\n",
    "This topic is explained in the third Statistics Prework Notebook, focusing on Statistical Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8e92b",
   "metadata": {
    "id": "5ba8e92b"
   },
   "source": [
    "## The cumulative density function: \n",
    "\n",
    "The cumulative density (CDF) function is a monotonically increasing function as it integrates over densities.\n",
    "\n",
    "To get an intuition of the CDF, let’s create a plot for some generated height data (normally distributed)\n",
    "\n",
    "Let's assume a height distribution can be modeled with a mean of 170cm and a standard deviation of 10cm. The corresponding density for range of heights from 120-220 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca7046",
   "metadata": {
    "id": "9aca7046"
   },
   "outputs": [],
   "source": [
    "height_ranges = range(120, 221)\n",
    "mean = 170\n",
    "std = 10\n",
    "\n",
    "pdf_densities = norm.pdf(height_ranges, loc=mean, scale=std)\n",
    "ax = sns.scatterplot(x=height_ranges, y=pdf_densities)\n",
    "ax.set(xlabel='Height', ylabel='Density');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbf24d",
   "metadata": {
    "id": "32dbf24d"
   },
   "source": [
    "Then using `norm.cdf()` to find the CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce184e",
   "metadata": {
    "id": "08ce184e"
   },
   "outputs": [],
   "source": [
    "cdf_densities = norm.cdf(height_ranges, loc=mean, scale=std)\n",
    "ax = sns.scatterplot(x=height_ranges, y=cdf_densities)\n",
    "ax.set(xlabel='Height', ylabel='Density');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d162963",
   "metadata": {
    "id": "0d162963"
   },
   "source": [
    "The CDF displayed here shows the probability of being the person with the height less than or equal to a given value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d87b9b",
   "metadata": {
    "id": "a3d87b9b"
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "Let's assume a height distribution can be modeled with a mean of 165 cm and a standard deviation of 15 cm. \n",
    "\n",
    "Assuming range of heights from 110-225, construct a PDF and CDF plot similar to what you learnt above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05fa0b",
   "metadata": {
    "id": "ce05fa0b"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "height_ranges = range(110, 226)\n",
    "mean = 165\n",
    "std = 15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a27e6",
   "metadata": {
    "id": "ab4a27e6"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ed514",
   "metadata": {
    "id": "439ed514"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Now find out what are the chances that a person is less than or equal to 190cm in the given sample of heights (`height_ranges`)\n",
    "\n",
    "Hint:\n",
    "\n",
    "Create a dataframe with two columns, one should hold the heights and the other the corresponding CDF densities.\n",
    "\n",
    "The row with height of 190 should give you the probabiity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8f053",
   "metadata": {
    "id": "f2e8f053"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b496f4",
   "metadata": {
    "id": "d8b496f4"
   },
   "source": [
    "You can verify your answer also using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597698a",
   "metadata": {
    "id": "7597698a"
   },
   "outputs": [],
   "source": [
    "norm.cdf(190, loc=165, scale=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690b1ab",
   "metadata": {
    "id": "5690b1ab"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "What are the chances that the person is between 170 and 180cm?\n",
    "\n",
    "Assume mean = 165 and std = 15 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931de0c",
   "metadata": {
    "id": "0931de0c"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b413474",
   "metadata": {
    "id": "4b413474"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "chances that person is above 200 cm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5d210",
   "metadata": {
    "id": "3cb5d210"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5faf66",
   "metadata": {
    "id": "fe5faf66"
   },
   "source": [
    "## The quantile function: \n",
    "\n",
    "Quantiles define a particular part of a dataset. \n",
    "\n",
    "If we divide a distribution into four equal portions, we will have four quartiles which is illustrated in the diagram below. \n",
    "\n",
    "The first quartile includes all values that are smaller than a quarter of all values. In a graphical representation, it corresponds to 25% of the total area of a distribution. The two lower quartiles comprise 50% of all distribution values. \n",
    "\n",
    "\n",
    "Some special quantiles are the quartile (4 quarters), the quintile (fifth) and percentiles (hundredth).\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/19GdJuf.png)\n",
    "\n",
    "The quantile function in python (`norm.ppf()`) is simply the inverse of the cumulative density function (`norm.cdf()`).\n",
    "\n",
    "Thus, the quantile function maps from probabilities to values.\n",
    "\n",
    "The input to the `norm.ppf()` function is one or a vector of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50cae3",
   "metadata": {
    "id": "7f50cae3"
   },
   "outputs": [],
   "source": [
    "# vector of probabilities from 0 to 1 with the step 0.01\n",
    "prob_ranges = np.arange(0, 1, 0.01)\n",
    "prob_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72d0df",
   "metadata": {
    "id": "7c72d0df"
   },
   "outputs": [],
   "source": [
    "mean = 165\n",
    "std = 15\n",
    "cdf_inverse = norm.ppf(prob_ranges, loc=mean, scale=std)\n",
    "\n",
    "ax = sns.scatterplot(x=prob_ranges, y=cdf_inverse);\n",
    "ax.set(xlabel='Probabilities', ylabel='Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e788b6",
   "metadata": {
    "id": "09e788b6"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Check if the probability obtained in the previous example with CDF (`norm.cdf`) will return the height we had as input by using the (`norm.ppf`) function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50090dc6",
   "metadata": {
    "id": "50090dc6"
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7007a4",
   "metadata": {
    "id": "9b7007a4"
   },
   "source": [
    "## Normal distribution with different parameters\n",
    "\n",
    "We will generate the following figure of a normal distribution with different parameters values using `norm.rvs()`.\n",
    "\n",
    "![](https://i.imgur.com/wY6er3R.png)\n",
    "\n",
    "\n",
    "\n",
    "### Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2897efe",
   "metadata": {
    "id": "e2897efe"
   },
   "outputs": [],
   "source": [
    "A = norm.rvs(size=100000, loc=0, scale=np.sqrt(0.2))\n",
    "B = norm.rvs(size=100000, loc=0, scale=np.sqrt(1))\n",
    "C = norm.rvs(size=100000, loc=0, scale=np.sqrt(5))\n",
    "D = norm.rvs(size=100000, loc=-2, scale=np.sqrt(0.5))\n",
    "\n",
    "fig = sns.kdeplot(A, shade=False, color=\"b\")\n",
    "fig = sns.kdeplot(B, shade=False, color=\"r\")\n",
    "fig = sns.kdeplot(C, shade=False, color=\"y\")\n",
    "fig = sns.kdeplot(D, shade=False, color=\"g\")\n",
    "plt.xlim([-5, 5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cbc21",
   "metadata": {
    "id": "307cbc21"
   },
   "source": [
    "# Multivariate Gaussian Distribution\n",
    "\n",
    "Thus far, we have seen distribution functions for single variable. It is possible to estimate probabaility distribution for multiple variables. These are called joint probabaility distributions, or multivariate distributions.\n",
    "\n",
    "\n",
    "A natural extension of the gaussian (normal) distribution that was covered earlier, is the multivariate gaussian distribution.\n",
    "\n",
    "The product of more than one gaussian is a multivariate gaussian with the following density function,\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "p(x ; \\mu, \\Sigma)=\\frac{1}{(2 \\pi)^{n / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(x-\\mu)^{T} \\Sigma^{-1}(x-\\mu)\\right)\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ = covariance matrix (often referred to as Kernel),\n",
    "\n",
    "and positive semi-indefinite $X = [X_1… X_n]$\n",
    "\n",
    "\n",
    "\n",
    "The figure below shows a univariate Gaussian density for a single variable $X$ on the left with a bell shaped curve.\n",
    "\n",
    "The multivariate Gaussian density over two variables $X_1$ and $X_2$ is shown on the right.\n",
    "\n",
    "![](https://i.imgur.com/Mt1wXSU.png)\n",
    "\n",
    "- Marginal (individual variable distribution) of a joint gaussian is gaussian\n",
    "\n",
    "- Multivariate gaussian concepts very useful to understand Gaussian Mixture Models and Gaussian Processes.\n",
    "\n",
    "\n",
    "\n",
    "The figure below shows a heatmap indicating values of the density function for a multivariate gaussian when the variables are not correlated and correlated.\n",
    "\n",
    "![](https://i.imgur.com/7z3xcCN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41f69a",
   "metadata": {
    "id": "3e41f69a"
   },
   "source": [
    "# Outliers, IQR, Boxplots and Violin Plots \n",
    "\n",
    "\n",
    "## Outliers\n",
    "\n",
    "An outlier is an observation point that is distant from other observations.\n",
    "\n",
    "An outlier may be due to:\n",
    "\n",
    "* variability in the measurement\n",
    "* experimental error \n",
    "\n",
    "(the latter are sometimes excluded from the data set)\n",
    "\n",
    "\n",
    "➔ An outlier can cause serious problems in statistical analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e4b2a",
   "metadata": {
    "id": "0f3e4b2a"
   },
   "source": [
    "## IQR\n",
    "\n",
    "The interquartile range (IQR) is a method to objectively identify outliers:\n",
    "\n",
    "A quantile defines a particular part of a data set, i.e. a quantile determines how many values in a distribution are above or below a certain limit. \n",
    "\n",
    "Special quantiles are the quartile (quarter), the quintile (fifth) and percentiles (hundredth).\n",
    "\n",
    "The difference between the 75th percentile (Q3) and 25th percentile (Q1) gives you the IQR. \n",
    "\n",
    "It is therefore the range spanned by the middle half of the data or the range between the lower and upper quartile (hence, interquartile range).\n",
    "\n",
    "Outliers are defined as: below Q1 − 1.5 x IQR or above Q3 + 1.5 x IQR. However this is not set in stone and you can modify this based on your data and take a call.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/b6yJDZO.png)\n",
    "\n",
    "\n",
    "\n",
    "Let's revisit our cars dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0017034",
   "metadata": {
    "id": "b0017034"
   },
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a632918",
   "metadata": {
    "id": "0a632918"
   },
   "source": [
    "Let's look at the distribution for `mpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac75a8",
   "metadata": {
    "id": "abac75a8"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(x='mpg', data=cars, shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6a3bd",
   "metadata": {
    "id": "5af6a3bd"
   },
   "source": [
    "We can also visualize the distribution as a boxplot as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da22903",
   "metadata": {
    "id": "7da22903"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='mpg', data=cars);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe73070",
   "metadata": {
    "id": "efe73070"
   },
   "source": [
    "We can compute specific quartiles (Q1 and Q3) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ab1ad",
   "metadata": {
    "id": "d77ab1ad"
   },
   "outputs": [],
   "source": [
    "Q1 = np.percentile(cars['mpg'], 25)\n",
    "Q3 = np.percentile(cars['mpg'], 75)\n",
    "Q3, Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89531",
   "metadata": {
    "id": "54b89531"
   },
   "source": [
    "IQR can then be computed using Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835bb6d",
   "metadata": {
    "id": "7835bb6d"
   },
   "outputs": [],
   "source": [
    "IQR = Q3 - Q1\n",
    "IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5124a6",
   "metadata": {
    "id": "4b5124a6"
   },
   "source": [
    "You can also use the following function to compute IQR directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2c5e2",
   "metadata": {
    "id": "b2c2c5e2"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "iqr(cars['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0557e64",
   "metadata": {
    "id": "a0557e64"
   },
   "source": [
    "We can see all quantiles by typing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce833b",
   "metadata": {
    "id": "43ce833b"
   },
   "outputs": [],
   "source": [
    "cars['mpg'].quantile(q=[0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa6d2c",
   "metadata": {
    "id": "21fa6d2c"
   },
   "source": [
    "Or just to see the 25% and 75% we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b21aa0",
   "metadata": {
    "id": "11b21aa0"
   },
   "outputs": [],
   "source": [
    "cars['mpg'].quantile(q=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68509ab6",
   "metadata": {
    "id": "68509ab6"
   },
   "source": [
    "Outliers and IQRs can be nicely visualized by boxplots (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1168e2",
   "metadata": {
    "id": "2e1168e2"
   },
   "source": [
    "## Exercise: Finding outliers and visualizing them\n",
    "\n",
    "Use the **starwars data set** (remember prep work number one?). \n",
    "\n",
    "Identify and remove outliers for the variable `mass`.   \n",
    "\n",
    "\n",
    "Let's start with loading the data and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187a66d",
   "metadata": {
    "id": "5187a66d"
   },
   "outputs": [],
   "source": [
    "starwars = pd.read_csv('data/pw_stats_01_star_wars.csv')\n",
    "starwars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9dc8b",
   "metadata": {
    "id": "e7e9dc8b"
   },
   "source": [
    "Now assign the `mass` dataframe column to the `mass_values` variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f6c62",
   "metadata": {
    "id": "939f6c62"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "mass_values = <YOUR CODE HERE>\n",
    "mass_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761925e1",
   "metadata": {
    "id": "761925e1"
   },
   "source": [
    "Now we see there are quite some values which are NaNs and so we can see exactly how many using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7290de",
   "metadata": {
    "id": "9c7290de"
   },
   "outputs": [],
   "source": [
    "mass_values.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b8935",
   "metadata": {
    "id": "fe2b8935"
   },
   "source": [
    "We can use the `dropna()` function as follows to clean our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deacc8f",
   "metadata": {
    "id": "6deacc8f"
   },
   "outputs": [],
   "source": [
    "clean_mass_values = mass_values.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f980bc6",
   "metadata": {
    "id": "5f980bc6"
   },
   "source": [
    "Try rechecking the number of null values present in `clean_mass_values` using the function we used earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d0782",
   "metadata": {
    "id": "029d0782"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456122ee",
   "metadata": {
    "id": "456122ee"
   },
   "source": [
    "Now plot a histogram for `clean_mass_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02872b4c",
   "metadata": {
    "id": "02872b4c"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4b2a5",
   "metadata": {
    "id": "83b4b2a5"
   },
   "source": [
    "Now plot a boxplot for `clean_mass_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c20510",
   "metadata": {
    "id": "54c20510"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634ee65",
   "metadata": {
    "id": "d634ee65"
   },
   "source": [
    "There are defintely some outliers in our data. Let's try to visualize the upper and lower limits of our data based on the boxplot outlier detection rule:\n",
    "\n",
    "- Upper Whisker (UW) in the box plot = Q3 + (1.5 x IQR)\n",
    "- Lower Whisker (LW) in the box plot = Q1 - (1.5 x IQR)\n",
    "\n",
    "Anything beyond UW or LW are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3be51",
   "metadata": {
    "id": "1aa3be51"
   },
   "source": [
    "Let's start by computing Q1 (25th percentile) and Q3 (75th percentile) of `clean_mass_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ef012",
   "metadata": {
    "id": "770ef012"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "Q1 = <YOUR CODE HERE>\n",
    "Q3 = <YOUR CODE HERE>\n",
    "Q3, Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b775b",
   "metadata": {
    "id": "a58b775b"
   },
   "source": [
    "Now compute the IQR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5d063",
   "metadata": {
    "id": "74d5d063"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "IQR = <YOUR CODE HERE>\n",
    "IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634880fc",
   "metadata": {
    "id": "634880fc"
   },
   "source": [
    "Compute the UW and LW values based on the above mentioned formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89f0fe",
   "metadata": {
    "id": "2b89f0fe"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "UW = <YOUR CODE HERE>\n",
    "LW = <YOUR CODE HERE>\n",
    "\n",
    "UW, LW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8fd92",
   "metadata": {
    "id": "f0d8fd92"
   },
   "source": [
    "We can now visualize the histogram with the whisker limits as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111f092",
   "metadata": {
    "id": "b111f092"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x=clean_mass_values);\n",
    "plt.axvline(LW, color='r')\n",
    "plt.axvline(UW, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8fd4d",
   "metadata": {
    "id": "91b8fd4d"
   },
   "source": [
    "We can now visualize the boxplot also with the whisker limits as follows:\n",
    "    \n",
    "It is quite evident that the black whiskers on the box plot by default are exactly the same as the red lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781da8d",
   "metadata": {
    "id": "c781da8d"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=clean_mass_values);\n",
    "plt.axvline(LW, color='r')\n",
    "plt.axvline(UW, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d729afa",
   "metadata": {
    "id": "9d729afa"
   },
   "source": [
    "We remove the outliers now using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8fe00",
   "metadata": {
    "id": "91b8fe00"
   },
   "outputs": [],
   "source": [
    "outliers_removed = clean_mass_values[(clean_mass_values <= UW) & (clean_mass_values >= LW)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16019dd4",
   "metadata": {
    "id": "16019dd4"
   },
   "source": [
    "Visualize the histogram of the `outliers_removed` variable now after we have removed the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d2a6d",
   "metadata": {
    "id": "365d2a6d"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0b1cc",
   "metadata": {
    "id": "bbb0b1cc"
   },
   "source": [
    "Visualize the boxplot of the `outliers_removed` variable now after we have removed the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb457b",
   "metadata": {
    "id": "14fb457b"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd7dbc",
   "metadata": {
    "id": "f4dd7dbc"
   },
   "source": [
    "As expected - the distributions look much cleaner!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c90a7",
   "metadata": {
    "id": "e36c90a7"
   },
   "source": [
    "## Violin Plots\n",
    "\n",
    "A violin plot is a blend of density and a boxplot! It is a mirrored density plot displayed in the same way as a boxplot and succinctly summarizes a continuous distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4a949",
   "metadata": {
    "id": "6dd4a949"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=outliers_removed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec961c",
   "metadata": {
    "id": "bbec961c"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=outliers_removed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a70ba8",
   "metadata": {
    "id": "b6a70ba8"
   },
   "source": [
    "# Other common distributions\n",
    "\n",
    "In the following sections, we go through examples of other common distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e845e",
   "metadata": {
    "id": "270e845e"
   },
   "source": [
    "## Bernoulli\n",
    "\n",
    "The Bernoulli distribution ($X \\sim {\\sf B}(1, p)$) is the discrete probability distribution of a random variable which takes the value 1 with probability p and the value 0 with probability q=1-p.\n",
    "\n",
    "Basically, a random experiment that has only two outcomes (usually called a “Success” or a “Failure”) will result in a Bernoulli distribution. \n",
    "\n",
    "For example, the probability of getting a heads (a “success”) while flipping a coin is 0.5. \n",
    "\n",
    "The probability of “failure” is 1 – P (1 minus the probability of success, which also equals 0.5 for a coin toss). \n",
    "\n",
    "Other examples can be the chance for a team to win a game, a student passing an exam, the gender of a child and many more.\n",
    "\n",
    "The PMF is given as  $$f(k;p) = \\begin{cases}\n",
    "        p & \\text{if } k=1\\\\\n",
    "        1-p & \\text{if } k=0\\\\\n",
    "        \\end{cases}$$\n",
    "\n",
    "Expectation: $E(X)=p$ \\\n",
    "Variance: $Var(X)=p(1-p)$\n",
    "\n",
    "The Bernoulli distribution is closely related to and a special case of the Binomial distribution (shown below). \n",
    "\n",
    "As long as each individual Bernoulli trial is independent, then the number of successes in a series of Bernoulli trials has a Binomial Distribution. \n",
    "\n",
    "The Bernoulli distribution can also be defined as the Binomial distribution with n = 1. \n",
    "\n",
    "In other words, it is a binomial distribution with a single trial (e.g. a single coin toss)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3967c",
   "metadata": {
    "id": "a6d3967c"
   },
   "source": [
    "You can generate a bernoulli distributed discrete random variable using `scipy.stats` `bernoulli.rvs()` method which takes `p` (probability of success) as a shape parameter. \n",
    "\n",
    "To shift the distribution you can always use the `loc` parameter for a custom mean and the `scale` parameter for a custom standard deviation. \n",
    "\n",
    "`size` decides the number of times to repeat the trials. \n",
    "\n",
    "If you want to maintain reproducibility, include a `random_state` argument assigned to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f2cc1",
   "metadata": {
    "id": "511f2cc1"
   },
   "outputs": [],
   "source": [
    "#Example: Generating random numbers of a Bernoulli distribution:\n",
    "from scipy.stats import bernoulli\n",
    "bern_outcomes = bernoulli.rvs(size=10000, p=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c926bae",
   "metadata": {
    "id": "6c926bae"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x=bern_outcomes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a0bf7",
   "metadata": {
    "id": "8b5a0bf7"
   },
   "source": [
    "Visulaizing the distribution, you can observe that you have only two possible outcomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e26ba7",
   "metadata": {
    "id": "10e26ba7"
   },
   "source": [
    "## Binomial\n",
    "\n",
    "The Binomial distribution ($X \\sim {\\sf B}(n, p)$) is an extension of the Bernoulli, where the trial is repeated n times. For example, a coin is tossed multiple times. The probability of success is the same in each trial and the trials are independent (outcome of one trial has no influence on the outcome of another trial).\n",
    "\n",
    "The PMF for the binomial distribution is given as: $$f(k,n,p) = Pr(X=k)= \\binom{n}{k}p^{k}(1-p)^{n-k}$$\n",
    "\n",
    "Expectation: $E(X)=np$ \\\n",
    "Variance: $Var(X)=np(1-p)$\n",
    "\n",
    "and can be visualized as in the following image:\n",
    "\n",
    "![](https://i.imgur.com/NQNbmT4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09565303",
   "metadata": {
    "id": "09565303"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Suppose there are twelve multiple choice questions in an English class quiz. \n",
    "\n",
    "Each question has five possible answers, and only one of them is correct. \n",
    "\n",
    "Find the probability of having four or less correct answers if a student attempts to answer every question at random.\n",
    "\n",
    "__Solution:__ \n",
    "\n",
    "Since only one out of five possible answers is correct, the probability of answering a question correctly by random is 1/5=0.2. \n",
    "\n",
    "We can find the probability of having exactly 4 correct answers by random attempts as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde6fb1",
   "metadata": {
    "id": "6dde6fb1"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "binom.pmf(n=12, p=0.2, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1c1ef",
   "metadata": {
    "id": "e7a1c1ef"
   },
   "source": [
    "To find the probability of having four or less correct answers by random attempts. \n",
    "\n",
    "We apply the function `binom.pmf()` with `x = 0, ...,4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3fcf0",
   "metadata": {
    "id": "8fe3fcf0"
   },
   "outputs": [],
   "source": [
    "binom.pmf(n=12, p=0.2, k=0) + \\\n",
    "binom.pmf(n=12, p=0.2, k=1) + \\\n",
    "binom.pmf(n=12, p=0.2, k=2) + \\\n",
    "binom.pmf(n=12, p=0.2, k=3) + \\\n",
    "binom.pmf(n=12, p=0.2, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1c20d",
   "metadata": {
    "id": "c8d1c20d"
   },
   "source": [
    "Alternatively, we can use the cumulative probability function for binomial distribution: `binom.cdf` and make it much simpler with just one line of code. \n",
    "\n",
    "Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91976dcb",
   "metadata": {
    "id": "91976dcb"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5ba5a",
   "metadata": {
    "id": "7bf5ba5a"
   },
   "source": [
    "Plotting the PMF of the binomial distribution (for example above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5d0e1",
   "metadata": {
    "id": "97e5d0e1"
   },
   "outputs": [],
   "source": [
    "k_values = np.arange(1,13)\n",
    "binom_pmfs = binom.pmf(k=k_values, n=12, p=0.2)\n",
    "ax = sns.scatterplot(x=k_values, y=binom_pmfs)\n",
    "ax.set(xlabel='x', ylabel='p(x)', title='PMF for Binomial (n=12, p=0.2)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b077c2a",
   "metadata": {
    "id": "2b077c2a"
   },
   "source": [
    "Plotting the CDF of the binomial distribution:\n",
    "\n",
    "The easiest way to plot the CDF for the binomial variable above it to view `binom.cdf(x, 12, 0.2)` as a function of real variable `x` plotted for `0.0 < x < 12.0` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909f4f3",
   "metadata": {
    "id": "8909f4f3"
   },
   "outputs": [],
   "source": [
    "k_values = np.arange(0.00, 12.01, 0.01)\n",
    "binom_pmfs = binom.cdf(k=k_values, n=12, p=0.2)\n",
    "ax = sns.lineplot(x=k_values, y=binom_pmfs)\n",
    "ax.set(xlabel='x', ylabel='F(x)', title='CDF for Binomial (n=12, p=0.2)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1637f",
   "metadata": {
    "id": "2ea1637f"
   },
   "source": [
    "## Poisson\n",
    "\n",
    "Poisson ($X \\sim {\\sf P}(\\lambda)$) is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space. \n",
    "\n",
    "It is used for counts. Examples can be the counts of a disease in a certain town, counts of fishes in a lake or number of products sold on a website. \n",
    "\n",
    "For the poisson distribution, there is only one parameter: mean and variance are the same: λ.\n",
    "\n",
    "This is rarely reflected in empirical data. \n",
    "\n",
    "To adjust for it, a dispersion parameter can be used or the more flexible negative binomial distribution.\n",
    "\n",
    "The PMF for the Poisson distribution is given as: $$f(k;\\lambda) = Pr(X=k)= \\frac{\\lambda^{k}e^{-\\lambda}}{k!}$$\n",
    "\n",
    "Expectation: $E(X)=\\lambda$ \\\n",
    "Variance: $Var(X)=\\lambda$\n",
    "\n",
    "![](https://i.imgur.com/vyFJJiE.png)\n",
    "\n",
    "\n",
    "In python since lambda is a keyword it is represented by mu ($\\mu$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d26d45",
   "metadata": {
    "id": "61d26d45"
   },
   "source": [
    "Plotting the PMF for the Poisson distribution for different lambdas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474db9b6",
   "metadata": {
    "id": "474db9b6"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "x = np.arange(0, 21)\n",
    "possion_pmfs1 = poisson.pmf(k=x, mu=1)\n",
    "possion_pmfs2 = poisson.pmf(k=x, mu=4)\n",
    "possion_pmfs3 = poisson.pmf(k=x, mu=10)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'x': x,\n",
    "    'pmf1': possion_pmfs1,\n",
    "    'pmf2': possion_pmfs2,\n",
    "    'pmf3': possion_pmfs3\n",
    "})\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3db3a6",
   "metadata": {
    "id": "db3db3a6"
   },
   "source": [
    "Melting the results to make it easier for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a671c",
   "metadata": {
    "id": "243a671c"
   },
   "outputs": [],
   "source": [
    "melted_df = result_df.melt('x', var_name='cols',  value_name='vals')\n",
    "melted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39033a",
   "metadata": {
    "id": "6f39033a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.pointplot(x='x', y='vals', data=melted_df, hue='cols');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee6c14",
   "metadata": {
    "id": "c3ee6c14"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "If there are twelve cars crossing a bridge per minute on average, find the probability of having seventeen or more cars crossing the bridge in a particular minute. Plot the corresponding distribution.\n",
    "\n",
    "Solution\n",
    "The probability of having sixteen or less cars crossing the bridge in a particular minute is given by the function ppois. To get the inverse probability of having 17 or more cars, use the upper tail of the probability density function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88a940",
   "metadata": {
    "id": "ae88a940"
   },
   "source": [
    "The probability of having <= 16 cars cross the bridge can be computed using the `possion.cdf()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eacc46",
   "metadata": {
    "id": "a9eacc46"
   },
   "outputs": [],
   "source": [
    "poisson.cdf(k=16, mu=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9bb103",
   "metadata": {
    "id": "8e9bb103"
   },
   "source": [
    "Thus the probability of 17 or more cars can be computed by taking the complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bb0a7",
   "metadata": {
    "id": "a37bb0a7"
   },
   "outputs": [],
   "source": [
    "1 - poisson.cdf(k=16, mu=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa2b7b",
   "metadata": {
    "id": "7efa2b7b"
   },
   "source": [
    "We can also do this directly using the `possion.sf()` survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c02be3",
   "metadata": {
    "id": "a4c02be3"
   },
   "outputs": [],
   "source": [
    "poisson.sf(k=16, mu=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd779d1",
   "metadata": {
    "id": "1bd779d1"
   },
   "outputs": [],
   "source": [
    "successes = np.arange(0, 26)\n",
    "poisson_pmfs = poisson.pmf(k=successes, mu=12)\n",
    "\n",
    "ax = sns.scatterplot(x=successes, y=poisson_pmfs)\n",
    "ax.set(xlabel='x', ylabel='F(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089f49f",
   "metadata": {
    "id": "8089f49f"
   },
   "source": [
    "## Exponential\n",
    "\n",
    "The exponential distribution ($X \\sim {\\sf Exp}(\\lambda)$) represents the time between events in a Poisson process. \n",
    "\n",
    "It can also be interpreted as given a failure rate, probability of success over time, t. It is also a one parameter distribution: mean = λ (sometimes 1/λ is used). \n",
    "\n",
    "Examples are: the amount of time (beginning now) until an earthquake occurs, amount of time that a car battery lasts,..\n",
    "\n",
    "The PDF for the Poisson distribution is given as:\n",
    "\n",
    "$$f(x;\\lambda) = \\begin{cases}\n",
    "        \\lambda e ^{-\\lambda x}& \\text{for } x\\ge0\\\\\n",
    "        0 & \\text{for } x<0\\\\\n",
    "        \\end{cases}$$\n",
    "\n",
    "Expectation: $E(X)=1/\\lambda$ \\\n",
    "Variance: $Var(X)=1/{\\lambda^2}$\n",
    "\n",
    "\n",
    "`scipy.stats` module's `expon` methods take parameter `scale` as its argument which is nothing but $1/\\lambda$ in the above equation.\n",
    "\n",
    "\n",
    "Plotting the exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7014a",
   "metadata": {
    "id": "f1c7014a",
    "outputId": "43a39424-cc59-4399-ba5c-a8a8853cec6b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18026/1888734896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexp_pdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_pdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "x = np.arange(0, 11)\n",
    "exp_pdfs = expon.pdf(x, scale=1)\n",
    "ax = sns.lineplot(x=x, y=exp_pdfs)\n",
    "ax.set(xlabel='x', ylabel='F(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7064fe",
   "metadata": {
    "id": "dd7064fe"
   },
   "source": [
    "Plotting exponential probability density function for different lamdas, play around with lambda and see how it changes the curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33541f28",
   "metadata": {
    "id": "33541f28"
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 6)\n",
    "exp_pdfs1 = expon.pdf(x, scale=1.5)\n",
    "exp_pdfs2 = expon.pdf(x, scale=1)\n",
    "exp_pdfs3 = expon.pdf(x, scale=0.5)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'x': x,\n",
    "    'pdf1': exp_pdfs1,\n",
    "    'pdf2': exp_pdfs2,\n",
    "    'pdf3': exp_pdfs3\n",
    "})\n",
    "\n",
    "melted_df = result_df.melt('x', var_name='cols',  value_name='vals')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.pointplot(x='x', y='vals', data=melted_df, hue='cols');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0a9ce",
   "metadata": {
    "id": "bab0a9ce"
   },
   "source": [
    "## Exercise\n",
    "Suppose the mean checkout time of a supermarket cashier is three minutes. Find the probability of a customer checkout being completed by the cashier in less than two minutes.\n",
    "\n",
    "Solution:\n",
    "\n",
    "Use the `expon.cdf()` function with the right values for x and scale based on the above info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea32f1",
   "metadata": {
    "id": "73ea32f1"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fe020",
   "metadata": {
    "id": "4c1fe020"
   },
   "source": [
    "##  Exercise:  Use case of Poisson and exponential distributions - Modeling Response Time on Servers\n",
    "\n",
    "Let’s assume that jobs arrive at a server (let's call it Propulsion computation server for now) and the arrival time follows the Poisson distribution i.e. \n",
    "\n",
    "average inter-arrival time $\\frac{1}{\\lambda}$. \n",
    "\n",
    "The job gets processed immediately if the server is free, otherwise it ends up in the queue. \n",
    "\n",
    "In such cases the processing time is assumed to be exponentially distributed with average processing time $\\frac{1}{\\mu}$. \n",
    "\n",
    "The response rate for any job depends upon $\\lambda$ and $\\mu$ i.e. \n",
    "\n",
    "Traffic intensity $I = \\frac{\\lambda}{\\mu}$ \n",
    "- if $I \\gt 1$ the arrival rate exceeds the average processing rate (hence one has to wait longer to get results back) \n",
    "- if $I = 1$ jobs get processed as soon as they arrive \n",
    "- and if $I < 1$ jobs are being processed faster than they arrive (server sitting idle). \n",
    "\n",
    "Using this information, answer the following questions\n",
    "\n",
    "Supposed that jobs arrive at the rate of 4 per minute, examine the queue length when the service rate is:\n",
    "\n",
    "* Part a - 3.8 per minute\n",
    "* Part b - 4 per minute\n",
    "* Part c - 4.2 per minute\n",
    "\n",
    "\n",
    "**Hint**: You will have to simulate 10000 points using `poisson.rvs()`. \n",
    "\n",
    "Plot your results.\n",
    "\n",
    "Once the results are obtained, compute: \n",
    "\n",
    "- the average number of jobs in the queue \n",
    "- average queuing time \n",
    "- the longest waiting time\n",
    "\n",
    "\n",
    "In the first part, we solved the exercise for you. In parts b and c, you will need to tweak the code only slightly to get to the correct results. \n",
    "\n",
    "Try to understand what's going on in the first part before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe82292",
   "metadata": {
    "id": "dbe82292"
   },
   "source": [
    "### Part a\n",
    "\n",
    "Service rate $μ = 3.8 < λ = 4$, the arrival rate.\n",
    "\n",
    "Therefore, the traffic intensity $I = \\frac{λ}{μ} ≈ 1.05 > 1$.\n",
    "\n",
    "In this case we would expect the queue to increase indefinitely.\n",
    "\n",
    "Remember λ is identified as `mu` in the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3231c9",
   "metadata": {
    "id": "2a3231c9"
   },
   "outputs": [],
   "source": [
    "arrivals = poisson.rvs(size=10000, mu=4, random_state=41)\n",
    "service = poisson.rvs(size=10000, mu=3.8, random_state=42)\n",
    "\n",
    "queue = np.zeros(10000)\n",
    "\n",
    "# first element in queue length is computed from first elements in arrivals and service\n",
    "queue[0] = max(arrivals[0] - service[0], 0)\n",
    "\n",
    "# now populating remaining elements in queue for queue length\n",
    "for t in range(1, 10000):\n",
    "    queue[t] =  max(queue[t-1] + arrivals[t] - service[t], 0)\n",
    "\n",
    "time = np.arange(0, 10000)\n",
    "ax = sns.lineplot(x=time, y=queue)\n",
    "ax.set(xlabel='Time', ylabel='Queue Length');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe3412",
   "metadata": {
    "id": "4afe3412"
   },
   "outputs": [],
   "source": [
    "print(\"average number of jobs in the queue :\", np.mean(queue))\n",
    "print(\"average queuing time :\", np.mean(queue)*(1/4))\n",
    "print(\"longest waiting time :\", max(queue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a53a14",
   "metadata": {
    "id": "81a53a14"
   },
   "source": [
    "#### Part b\n",
    "\n",
    "Queue length when the traffic intensity = 1\n",
    "\n",
    "service rate $μ = 4$ and $λ = 4$ arrival rate.    \n",
    "Traffic intensity: $I =\\frac{λ}{μ}=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4e43d",
   "metadata": {
    "id": "a9a4e43d"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f08df9",
   "metadata": {
    "id": "a4f08df9"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd274b3e",
   "metadata": {
    "id": "cd274b3e"
   },
   "source": [
    "#### Part c\n",
    "\n",
    "service rate $μ = 4.2 > λ = 4$ arrival rate    \n",
    "Traffic intensity $I = \\frac{λ}{μ} < \\frac{4}{4.2} ≈ 0.95 < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d222589",
   "metadata": {
    "id": "2d222589"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40e6fd",
   "metadata": {
    "id": "6e40e6fd"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of pw_stats_02_descriptive_statistics.ipynb",
   "provenance": [
    {
     "file_id": "18lICs09KVAN88uJFToYAyhJM-u83Dw9l",
     "timestamp": 1630679091921
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
