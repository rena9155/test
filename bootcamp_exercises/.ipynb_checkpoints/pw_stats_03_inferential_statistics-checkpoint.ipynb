{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e98413",
   "metadata": {
    "id": "b6e98413"
   },
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "In this third tutorial notebook we introduce you to the statistical concepts required for **Statistical Inference** in data science.\n",
    "\n",
    "\n",
    "## What is Statistical Inference?\n",
    "\n",
    "Statistical inference describes the process where conclusions about a population can be formed, based on certain statistics calculated from a sample of that population.\n",
    "\n",
    "It focuses around three major goals:\n",
    "   1. Estimation of unknown parameters of the statistical model\n",
    "   2. Select the best model for your data\n",
    "   3. Do predictions with your model\n",
    "\n",
    "And the two main approaches to statistical inference are:\n",
    "  - Likelihood inference\n",
    "  - Bayesian inference\n",
    "\n",
    "There are important statistical concepts that need to be understood in order to make statistical inference. The following concepts will be covered initially:    \n",
    "  - [Law of Large Numbers (LLN)](#Law-of-Large-Numbers-(LLN))     \n",
    "  - [Central Limit Theorem (CLT)](#Central-Limit-Theorem-(CLT))     \n",
    "  - [Estimation](#Estimation)     \n",
    "  - [Frequentist vs Bayesian Approach to Statistical Inference](#Frequentist-vs-Bayesian-Approach-to-Statistical-Inference)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71fffe",
   "metadata": {
    "id": "8a71fffe"
   },
   "source": [
    "# Law of Large Numbers (LLN)\n",
    "\n",
    "The LLN theorem treats about an experiment that is repeated large number of times. \n",
    "\n",
    "It states: **the relative frequency of an event A approaches its true probability as the number of trials increases**.  \n",
    "  \n",
    "For this to be true, all trials must be identical and independent.\n",
    "\n",
    "Mathematically: \\\n",
    "$$\\overline{x} \\to \\mu$$  \n",
    "as   \n",
    "$$n \\to \\infty$$\n",
    "$$\\overline{x} = \\frac{\\sum_{i=1}^{n}(x_{i})}{n}$$\n",
    "\n",
    "where $\\mu$ is the true average, $n$ is the number of trials, and $x_{i}$ is the experiment value in trial $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80200988",
   "metadata": {
    "id": "80200988"
   },
   "source": [
    "## LLN Example - Rolling dice\n",
    "To illustrate the LLN with an example of rolling a die, we can ask the question,\n",
    "what would be the expected average outcome of rolling a dice?\n",
    "\n",
    "(1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.5\n",
    "*We already know this before the experiment is performed!*\n",
    "\n",
    "According to LLN, when we throw the dice a large number of times, the average of the observed outcomes will be close to expected value. The more times we throw the dice, the closer sample mean gets to the true mean, following the green line on the graph below\n",
    "\n",
    "\n",
    "![Source: https://en.wikipedia.org/wiki/Law_of_large_numbers](https://i.imgur.com/G5Avq9O.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648be02",
   "metadata": {
    "id": "2648be02"
   },
   "source": [
    "# Central Limit Theorem (CLT) \n",
    "\n",
    "The central limit theorem is a key concept in probability theory. Did you ever wonder why you hear so much about normal distribution, but not other distributions?\n",
    "The answer is behind central limit theorem.\n",
    "\n",
    "The theorem states that **the sampling distribution of the sample mean is at least approximately, normally distributed, regardless of the distribution of the underlying random sample**\n",
    "Again, it holds for variables that are independent and identically distributed.\n",
    "\n",
    "This is very powerful statement. Assume you will repeat certain experiment many times. At each step you will calculate mean value for this experiment. The distribution of this mean will always be approximately normal. **It doesn't matter what your underlying distribution is.**\n",
    "It implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions. Even when this distribution is complicated, or unknown.\n",
    "\n",
    "\n",
    "![Source: https://en.wikipedia.org/wiki/Central_limit_theorem](https://i.imgur.com/kGryqBl.png)\n",
    "\n",
    "The graphs below demonstrate that the frequency of numbers generated from a normal distribution using `norm.rvs()`, tends to a normal distribution (bell shaped curve), with an increasing number of repetitions (from 10 to 10000).\n",
    "\n",
    "![](sns_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8b011",
   "metadata": {
    "id": "d0a8b011"
   },
   "source": [
    "## Theorem\n",
    "\n",
    "Let's get back to law of large numbers. According to it, the population mean $\\mu$ can be approximated by the mean of the sampling distribution:\n",
    "\n",
    "$$\\mu_M = \\mu$$\n",
    "\n",
    "The variance of the sampling distribution is defined as the population variance divided by the sample size:\n",
    "\n",
    "$$\\sigma^{2}_M = \\frac{\\sigma^{2}}{N}$$\n",
    "\n",
    "The standard deviation of the sampling distribution of the mean is then:\n",
    "\n",
    "$$\\sigma_{M}=\\frac{\\sigma}{\\sqrt{N}}$$\n",
    "\n",
    "\n",
    "The larger the sample size, the smaller the standard deviation of the sampling distribution of the mean.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/TJHI1oF.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d809e2",
   "metadata": {
    "id": "f2d809e2"
   },
   "source": [
    "## Rolling dice CLT Example\n",
    "\n",
    "The CLT states that if n is large enough (rule of thumb: n > 30), the sample mean \n",
    "\n",
    "$\\overline{\\mathbf{X}}$ \n",
    "\n",
    "has a normal distribution (bell curve)\n",
    "\n",
    "In the diagram below, as the number of die rolls (samples) increases, the sampling distribution becomes closer to normal distribution.\n",
    "\n",
    "\n",
    "![Source: http://www.muelaner.com/wp-content/uploads/2013/07/central-limit-theorem.png](https://i.imgur.com/IX7VlI3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb3d23",
   "metadata": {
    "id": "3bcb3d23"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Consider taking random samples of various sizes n from an exponential distribution. \n",
    "\n",
    "At what sample size n does the normal distribution make a good approximation to the actual distribution of the sample mean?  \n",
    "\n",
    "Plot the histogram of the sample means.   \n",
    "\n",
    "Outline your approach in detail.\n",
    "\n",
    "Hint: first read the two examples of a possible approach: https://online.stat.psu.edu/stat414/lesson/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dbcb8",
   "metadata": {
    "id": "e94dbcb8",
    "outputId": "4645af06-91a1-45f4-83e0-9370c67b6e3f"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-59937f3ec561>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-59937f3ec561>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    <YOUR CODE HERE>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Central Limit Theorem: Simulate an Exponential Distribution\n",
    "from scipy.stats import expon\n",
    "\n",
    "# Number of samples and lambda value (mean) \n",
    "# these parameters are going to be used to draw from an exponential distribution\n",
    "n = 40\n",
    "lambda_val = 0.2\n",
    "mean_val = 1 / lambda_val\n",
    "\n",
    "# Draw randomly from the exponential distribution, compute mean of the sample and repeat 100000 times\n",
    "means = []\n",
    "\n",
    "for i in range(100000):\n",
    "    <YOUR CODE HERE>\n",
    "\n",
    "# compute mean of sample means    \n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d352742",
   "metadata": {
    "id": "2d352742"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcf34f",
   "metadata": {
    "id": "7edcf34f",
    "outputId": "6630b415-e5b0-4c12-de9f-cec06b73d98e"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d94ebb325df0>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d94ebb325df0>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    <YOUR CODE HERE>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# your code to create plot here\n",
    "\n",
    "# visualize means in a histogram along with actual mean value and mean of sample means\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31516b66",
   "metadata": {
    "id": "31516b66"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Sampling Distribution\n",
    "Assume that the weights of 10-year-old children are normally distributed with a mean of 90 and a standard deviation of 36. \n",
    "\n",
    "What is the sampling distribution of the mean for a sample size of 9? \n",
    "\n",
    "What are its mean, and standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ae1da",
   "metadata": {
    "id": "4f2ae1da"
   },
   "source": [
    "__Your Solution here:__\n",
    "    \n",
    "The mean of the sampling distribution of the mean is also 90. \n",
    "\n",
    "The standard deviation of the sampling distribution of the mean is sigma = 36/sqrt(9) = 12\n",
    "\n",
    "Therefore, the sampling distribution of the mean is a normal distribution N(90,144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa910500",
   "metadata": {
    "id": "aa910500"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "pop_mean = 90\n",
    "pop_std = 36\n",
    "sample_size = 9\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96649a55",
   "metadata": {
    "id": "96649a55"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a53a796",
   "metadata": {
    "id": "5a53a796"
   },
   "source": [
    "## Summary of LLN and CLT\n",
    "\n",
    "Both theorems tell us that given a sufficiently large amount of data points, those data points will result in predictable behaviors.\n",
    "\n",
    "* CLT shows that as a sample size tends to infinity, the **shape of the sample mean distribution will approach the normal distribution.**\n",
    "* LLN shows you where the **center of that normal curve** is likely to be located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3f2ca",
   "metadata": {
    "id": "c8e3f2ca"
   },
   "source": [
    "# Estimation\n",
    "\n",
    "**Estimation** is a data analysis framework for planning experiments, analyzing data and interpreting results.   \n",
    "There are numerous estimation procedures that can be used to calculate the value of some property of a population from observations of a sample drawn from the population.      \n",
    "An estimate of a population parameter may be expressed in two ways: [point estimates](#point_estimates) and [interval estimates](#interval_estimates), which are covered below.\n",
    "\n",
    "**The main point of estimation is to draw information from obtained data**.  \n",
    "\n",
    "\n",
    "**Statistical inference** refers to the process of drawing **conclusions from the model estimation.**\n",
    "\n",
    "\n",
    "Keep in mind: any data is considered a realization of a random variable coming from a certain distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc455246",
   "metadata": {
    "id": "dc455246"
   },
   "source": [
    "## Estimators and Estimates\n",
    "\n",
    "Everything in machine learning revolves around estimating parameters. You will often hear about weights or coefficients in neural networks. Those are the estimates.\n",
    "\n",
    "Now, let's make a distinction between an estimate and an estimator.\n",
    "\n",
    "**An Estimator:** is a statistic (arbitrary function of a random sample), used to extract information of a parameter from the random sample.\n",
    "It is expressed as a function of X.\n",
    "\n",
    "**An Estimate:** is the value of the evaluated estimator computed based on the data (realizations of the random sample)\n",
    "It is computed based on $x_1, x_2, ..., x_n$\n",
    "and is usually denoted by $\\hat{\\theta}$ for a parameter $\\theta$\n",
    "\n",
    "An estimator is a function, and an estimate is a value of this function. Usually we are interested in estimates that maximize certain function.\n",
    "\n",
    "Training machine learning models is simply a process of finding the best estimates.\n",
    "\n",
    "\n",
    "There are two types of estimates: \n",
    "\n",
    "  * Point estimate: single value \n",
    "  * Interval estimate: defined by lower and upper limit\n",
    "\n",
    "![Source: http://www.cqeacademy.com/wp-content/uploads/2017/12/Point-Estimate-Interval-Estimate.jpg](https://i.imgur.com/2RdEuDg.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfe4ab",
   "metadata": {
    "id": "ccbfe4ab"
   },
   "source": [
    "## Point Estimates \n",
    "\n",
    "\n",
    "**A point estimator uses the sample data to calculate a single value for the \"best guess\" of an unknown parameter.**\n",
    "\n",
    "An example of a point estimator of the population mean is the sample mean: $\\bar{X}=\\frac{1}{n} \\sum X_{i}$\n",
    "\n",
    "A sample of height 34 male freshman students was obtained:\n",
    "\n",
    "![](https://i.imgur.com/CjmDfUq.png)\n",
    "\n",
    "\n",
    "If one wanted to estimate the true mean of all male freshman students, you mgight use the sample mean as apoint estimator of the true mean:\n",
    "\n",
    "Sample mean = $\\bar{x}$ = 182.44\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e00d00",
   "metadata": {
    "id": "35e00d00"
   },
   "source": [
    "## Interval Estimates \n",
    "\n",
    "**In contrast to point estimation, interval estimators use the sample data to calculate an interval of possible values of an unknown parameter.**\n",
    "\n",
    "\n",
    "This means that the interval for the \"best guess\" of the unknown parameter also comes with a **confidence interval (when using frequentist methods)**, which is the confidence level that the true parameter is inside the proposed range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90233b7a",
   "metadata": {
    "id": "90233b7a"
   },
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "**A confidence interval refers to the probability that a population parameter will fall between a set of values for a certain proportion of times.**\n",
    "\n",
    "The confidence interval is used to measure the degree of uncertainty or certainty in a sampling method and can take any number of probability limits, with the most common being a 95% or 99% confidence level.\n",
    "\n",
    "Confidence intervals are conducted using statistical methods, such as a t-test.\n",
    "\n",
    "**Remember: interval estimates have an attached confidence level used to express the precision and uncertainty associated with a particular sampling method.**\n",
    "\n",
    "\n",
    "To summarize, interval estimate consists of three parts:  \n",
    "\n",
    "  1. Statistic: point estimate     \n",
    "  2. The confidence level: commonly 95%     \n",
    "  3. Margin of error: critical value x standard deviation     \n",
    "\n",
    "\n",
    "![](https://i.imgur.com/h8Hs107.png)\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/afR9sOM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09345544",
   "metadata": {
    "id": "09345544"
   },
   "source": [
    "### Example: Confidence Interval under Normal Distribution\n",
    "\n",
    "As mentioned above, a confidence interval refers to the probability that a population parameter will fall between a set of values for a certain proportion of times. \n",
    "\n",
    "Therefore, a 95% confidence interval for the standard normal distribution is the interval (-1.96, 1.96), since 95% of the area under the curve falls within this interval. \n",
    "\n",
    "This is illustrated in the image below. Remember that the standard normal distribution has \n",
    "\n",
    "mean = 0 and standard deviation = 1. \n",
    "\n",
    "\n",
    "![](https://i.imgur.com/z2Ypxz3.png)\n",
    "\n",
    "\n",
    "To calculate the 95% confidence interval for the standard normal that we can see in the image above, we can use the `norm.ppf()` function. \n",
    "\n",
    "\n",
    "Remember that `norm.ppf()` returns a value in standard deviations. \n",
    "\n",
    "The input to the `norm.ppf()` function is the confidence interval we wish to find converted into decimal.    \n",
    "\n",
    "However, we must remember that the confidence interval is spread around the mean, which means that we must deduct half the unwanted area off each side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb969cf6",
   "metadata": {
    "id": "bb969cf6"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.ppf(0.975) #95% confidence interval, right side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0793cc0",
   "metadata": {
    "id": "f0793cc0"
   },
   "outputs": [],
   "source": [
    "norm.ppf(0.025) #95% confidence interval, left side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd50b90",
   "metadata": {
    "id": "bbd50b90"
   },
   "source": [
    "### Exercise\n",
    "Point and interval estimates\n",
    "State for each statement whether it is TRUE or FALSE and explain why.\n",
    "\n",
    "a. When the margin of error is small, the confidence level is high.\n",
    "\n",
    "__Your Solution here:__\n",
    "\n",
    "\n",
    "\n",
    "b. The 95% CI is wider than the 99% CI (given all the rest the same).\n",
    "\n",
    "__Your Solution here:__\n",
    "\n",
    "\n",
    "\n",
    "c. When the margin of error is large, the confidence interval is large (wide).\n",
    "\n",
    "__Your Solution here:__\n",
    "\n",
    "\n",
    "\n",
    "d. If the sample size increases, the CI becomes wider.\n",
    "\n",
    "__Your Solution here:__\n",
    "\n",
    "\n",
    "\n",
    "e. A confidence interval is a point estimator.\n",
    "\n",
    "__Your Solution here:__\n",
    "\n",
    "\n",
    "\n",
    "f. A sample mean is an example of a point estimator.\n",
    "\n",
    "__Your Solution here:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4b4a8",
   "metadata": {
    "id": "4bb4b4a8"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Confidence intervals\n",
    "A population is known to be normally distributed.\n",
    "\n",
    "Compute the 95% confidence interval on the mean based on the following sample of nine: `[8, 9, 10, 13, 14, 16, 17, 20, 21]`\n",
    "\n",
    "Now compute the 99% confidence interval using the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538af9a2",
   "metadata": {
    "id": "538af9a2"
   },
   "outputs": [],
   "source": [
    "samples = [8, 9, 10, 13, 14, 16, 17, 20, 21]\n",
    "\n",
    "# your code here\n",
    "\n",
    "#Confidence Intervals\n",
    "\n",
    "#a) Compute the 95% confidence interval on the mean based on the following sample of nine: 8, 9, 10, 13, 14, 16, 17, 20, 21.\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "#remember for 95% conf interval on two sides we use norm.ppf(0.975) \n",
    "#Because we deduct half of 0.05 from both upper and lower end, instead of deducting the whole 0.05 from one end. \n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d3c8c",
   "metadata": {
    "id": "dc4d3c8c"
   },
   "outputs": [],
   "source": [
    "#remember for 99% conf interval on two sides we use norm.ppf(0.995) \n",
    "#Because we deduct half of 0.01 from both upper and lower end, instead of deducting the whole 0.01 from one end. \n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778e878",
   "metadata": {
    "id": "0778e878"
   },
   "source": [
    "## Construction of Estimators: Methods\n",
    "\n",
    "* **Maximum likelihood:**\n",
    "  Finds maximum of the likelihood function to estimate parameters of probabaility distribution. Its goal is to find a model under which observed data is most probabale.\n",
    "\n",
    "* **Method of Moments:**\n",
    "  Equates values of sample moments to population moments. Moments are the functions describing the parameter. Mean, Variance, Skewness, and Kurtosis are all moments.\n",
    "\n",
    "* **Bayesian Methods:**\n",
    "  Introducing a frequency function for the parameter being estimated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c5edd",
   "metadata": {
    "id": "428c5edd"
   },
   "source": [
    "## Good Estimators\n",
    "\n",
    "The two main characteristics of what a \"good\" estimator is, are consistency and unbiased.\n",
    "\n",
    "\n",
    "### Consistency\n",
    "\n",
    "**Consistency:** the larger the sample size the more “accurate” the estimate.\n",
    "\n",
    "The more data you collect, a consistent estimator will be close to the real population parameter you’re trying to measure.\n",
    "\n",
    "![](https://i.imgur.com/YaoQYKk.png)\n",
    "\n",
    "\n",
    "\n",
    "### Unbiased\n",
    "\n",
    "**Unbiased:** the expected value equals the true value.\n",
    "\n",
    "On average, it hits the true parameter value. Independent of sample size.\n",
    "For an unbiased estimator we are looking for the most efficient (estimates the quantity of interest in some “best possible” manner.)\n",
    "\n",
    "![](https://i.imgur.com/RogUIrc.png)\n",
    "\n",
    "\n",
    "\n",
    "### Example of \"good estimator\"\n",
    "\n",
    "![Source: https://eranraviv.com/wp-content/uploads/2014/05/Unbiased-and-Consistent.png](https://i.imgur.com/XYJbtuq.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb5d54",
   "metadata": {
    "id": "48bb5d54"
   },
   "source": [
    "# Frequentist vs Bayesian Approach to Statistical Inference\n",
    "\n",
    "Both the frequentist and bayesian inference approaches assess the probability of future observations based on some observations or hypothesis.\n",
    "\n",
    "**The frequentist approach does this by interpreting the likelihood of an event as relative frequency of the incidences of the event in similar and independently repeated experiments.** \n",
    "\n",
    "In short, according to the frequentist definition of probability, only repeatable random events (like the result of flipping a coin) have probabilities. These probabilities are equal to the long-term frequency of occurrence of the events in question.\n",
    "\n",
    "This approach starts with an abstract experiment of what would be observed if one assumes something, and only then compares the outcomes of the abstract experiment with what was actually observed.\n",
    "\n",
    "\n",
    "**The Bayesian approach on the other hand, starts from what has been observed and assesses possible future outcomes.**\n",
    "\n",
    "A summary of the differences and similarities between the two approaches is listed here:\n",
    "\n",
    "![](https://i.imgur.com/hIvZ6Hh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f0588",
   "metadata": {
    "id": "a32f0588"
   },
   "source": [
    "## Bayes' Rule \n",
    "\n",
    "The Bayesian approach to statistical inference is based on the Bayes' Rule:\n",
    "$$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n",
    "where:\n",
    "\n",
    "  - $A$ and $B$ are events\n",
    "  - $P(B)$ is not $0$\n",
    "\n",
    "$P(A)$ and $P(B)$ are the unconditional probabilities of A and B occurring\n",
    "$P(A|B)$ is the conditional probability of A occurring, given that B occurs\n",
    "$P(B|A)$ is the conditional probability of B occurring, given that A occurs\n",
    "\n",
    "$P(B) = P(B|A)*P(A) + P(B|A-)*P(A-)$\n",
    "\n",
    "$P(A|B) = 1 - P(A-|B)$\n",
    "\n",
    "**Bayesians view probabilities as a more general concept. You can use probabilities to represent the uncertainty in any event or hypothesis.**\n",
    "\n",
    "\n",
    "Another way of looking at the Bayes' formula when data is involved, is that the newly collected data makes the probability distribution over the parameter’s true (unknown) value narrower. \n",
    "\n",
    "You do the updating process from newly collected data by applying Bayes’ theorem to each possible value of the parameter, to update the entire probability distribution:\n",
    "\n",
    "$$P(Parameter | Data)=\\frac{P(Data | parameter) P(Parameter)}{P(Data)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00fb6c",
   "metadata": {
    "id": "9a00fb6c"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Solve the following questions using the [bayes rule](#Bayes'-Rule) from above.\n",
    "\n",
    "If the probability of spots given smallpox is 0.9, the probability to smallpox is 0.001, and the probability of spots in 0.081\n",
    "\n",
    "What is the probability of smallpox given spots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0089e",
   "metadata": {
    "id": "a3d0089e"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "\n",
    "#likelihood = prob of spots given smallpox.\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "#prior = prob of smallpox.\n",
    "\n",
    "\n",
    "# marginal likelihood = prob of spots.\n",
    "\n",
    "\n",
    "# find posterior = prob of smallpox given spots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a74ff",
   "metadata": {
    "id": "276a74ff"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Following on the exercise above, if the probability of spots given chicken pox is 0.8, and the probability of chickenpox is 0.1\n",
    "\n",
    "What is the probability of chickenpox given spots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa20f85",
   "metadata": {
    "id": "6fa20f85"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87c4ff",
   "metadata": {
    "id": "ae87c4ff"
   },
   "source": [
    "This chapter on Frequentist vs Bayesian inference serves as only an introduction to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aae431",
   "metadata": {
    "id": "b8aae431"
   },
   "source": [
    "# Inferential Statistics\n",
    "\n",
    "\n",
    "**Inferential statistics** is the process of taking samples from a larger population and using that data to draw conclusions about the population, make decisions on the basis of those conclusions, and even predict future behaviour.\n",
    "\n",
    "In other words, inferential statistics is the logical process of drawing general conclusions based on specific pieces of information (data)\n",
    "\n",
    "\n",
    "There are important statistical concepts that need to be understood in order to make inductive reasoning.\n",
    "\n",
    "The following concepts will be covered here:\n",
    "  - [Experimental Design](#Experimental-Design)\n",
    "  - [Bootstrapping](#Bootstrapping)\n",
    "  - [Permutation Tests](#Permutation-Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa0d86",
   "metadata": {
    "id": "53aa0d86"
   },
   "source": [
    "# Experimental Design \n",
    "\n",
    "\n",
    "**Experimental design refers to how participants are allocated to the different groups in an experiment.**\n",
    "\n",
    "We do experiments to learn about causality, not just correlation, between variables.\n",
    "\n",
    "![source: https://imgs.xkcd.com/comics/correlation.png](https://i.imgur.com/YNA7Ydk.png)\n",
    "\n",
    "**Experiments test whether the independent variable has an effect on the dependent variable in the hypothesis.**\n",
    "\n",
    "Levels of the independent variable are randomly assigned, and the dependent variable is measured.\n",
    "\n",
    "\n",
    "For example, we may wish to test the hypothesis:\n",
    "“Vitamins make you smarter”\n",
    "\n",
    "In order to do this, we will need to design the experiment in a way that allocates participants into different groups.\n",
    "\n",
    "![](https://i.imgur.com/FFSQxGZ.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e445d98",
   "metadata": {
    "id": "1e445d98"
   },
   "source": [
    "## Common Experimental Designs\n",
    "\n",
    "\n",
    "Two common experimental designs are the A/B and A/A testing.\n",
    "\n",
    "\n",
    "**A/B Testing** is (also known as split testing) allocates one group of participants to variant A and the other group of participants to variant B of the experiment. This allows the designer to compare two versions of a single variable to determine which one of the two variants is more effective.\n",
    "\n",
    "\n",
    "**A/A Testing** splits participants into two different groups, but applies them the same treatment.\n",
    "\n",
    "\n",
    "Participants will first be treated with one variant of the experiment, and then with another. \n",
    "\n",
    "The A/A test is used to validate the results of A/B test.\n",
    "\n",
    "We want to see if there is noise in the data, instead of signal. \n",
    "\n",
    "Comparing results of A/A and A/B tests allows you to quickly see whether the treatment indeed had an effect.\n",
    "\n",
    "Ideally you want to find that there is no difference between both groups in A/A test. \n",
    "\n",
    "Seeing that you get roughly the same performance from each variant allows you to validate setup for A/B test.\n",
    "\n",
    "\n",
    "The experiments can also be setup as:\n",
    "\n",
    "**Between subjects:** Participants are split into two groups. Each group receives different variant of a treatment. Comparing results of each groups allows you to draw conculsion on how effects of two variants vary.\n",
    "Between subject tests are great to get an unbiased view of what approach works.\n",
    "\n",
    "\n",
    "**Within subjects:** All participants get both variants of a treatment. First they will be exposed to variant A, and then to the variant B. Relevant metrics are collected after every stage.\n",
    "Within subject studies are great when you need an exact comparison. They are, however, more prone to bias.\n",
    "\n",
    "\n",
    "In our vitamins example, between subjects and within subjects experiments could be set up like this:\n",
    "\n",
    "![](https://i.imgur.com/0a4XtW9.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c62b8a",
   "metadata": {
    "id": "69c62b8a"
   },
   "source": [
    "## Treatment and Control Groups\n",
    "\n",
    "The **treatment group** is the group that will be applied a manipulation (also called treatment conditions)\n",
    "\n",
    "\n",
    "The **control group** is the group where no intervention is made.\n",
    "This group is used to remove concerns about the effects of merely participating in the study.\n",
    "\n",
    "\n",
    "The **control conditions** of the control group are very important because minimize the changes in all other variables except the one being tested during an experiment.\n",
    "\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/jEYj3Cl.png)\n",
    "\n",
    "In our vitamins example, good control conditions would allow to vary ONLY the independent variable, i.e. the pills type.\n",
    "\n",
    "\n",
    "We don’t want to test whether eating something affects intelligence, or whether sitting in the lab for a while affects intelligence. We want to be sure that any changes in the dependent variable (IQ) seen in the treatment group are a result of the independent variable (vitamins) only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b2989",
   "metadata": {
    "id": "e05b2989"
   },
   "source": [
    "## Randomized Controlled Trial (RCT)\n",
    "\n",
    "A randomized controlled trial (RCT) is an experiment performed on human subjects (usually patients or customers) in order to assess the efficacy of a treatment (or intervention) for some condition.\n",
    "\n",
    "Two key features:\n",
    "1. The new treatment is given to a group of patients, the treated group, and another treatment (standard or placebo treatment) is given to another group of patients, the control group, at the same time.\n",
    "\n",
    "2. Patients are allocated to one group or another by randomization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616d121",
   "metadata": {
    "id": "2616d121"
   },
   "source": [
    "### Example\n",
    "\n",
    "A company developed a new pacemaker. In order to get market approval they need to show that the new pacemaker is as good and as safe as the existing pacemaker, also referred as gold standard.\n",
    "\n",
    "They have to enrol a certain amount of subjects (defined by a sample size calculation, see later).\n",
    "\n",
    "The enrolled subjects are randomized to either the new pacemaker or the gold standard.\n",
    "\n",
    "Both groups need to be treated exactly the same, of course except of the implanted pacemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948d6cb",
   "metadata": {
    "id": "7948d6cb"
   },
   "source": [
    "## Random Assignment\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Do these methods represent a way to randomly assign conditions?\n",
    "\n",
    "  - Hour of day the participant enters the study. \n",
    "  - Participant’s choice of whether to have the treatment. \n",
    "  - Date the participant signed up for your website. \n",
    "  - 50% of participants chosen through a random generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c8d81",
   "metadata": {
    "id": "3e3c8d81"
   },
   "source": [
    "__Your Answers Here__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d5b1a",
   "metadata": {
    "id": "540d5b1a"
   },
   "source": [
    "## Blinding\n",
    "\n",
    "Blinding means that all information about the group allocation is kept away from the study participant, to reduce or eliminate bias.\n",
    "\n",
    "**Single-blinded**: Patients have no information that could influence the results, e.g. the received treatment.\n",
    "\n",
    "**Double-blinded**: Patients and experimenter have no information that could influence the results.\n",
    "\n",
    "**Triple-blinded**: Patients , experimenter and the committee monitoring the study have no information that could influence the results.\n",
    "\n",
    "The analyst/data scientist should always be blinded!\n",
    "\n",
    "Especially if s/he is working for a company which is dependent on the outcome of the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5dc56b",
   "metadata": {
    "id": "bb5dc56b"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "You have developed a new flu vaccine. In order to test the effectiveness of your new treatment, you run an experiment, giving half of your participants the flu vaccine and the other half a fake vaccine that will have no effect.\n",
    "\n",
    "- Is this single, double, or tripe blinding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adea42",
   "metadata": {
    "id": "28adea42"
   },
   "source": [
    "__Your Answers Here:__\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b9147",
   "metadata": {
    "id": "287b9147"
   },
   "source": [
    "Why is it important for your study, that participants in the control group do not realize they have received a fake vaccine and are not protected against the flu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c843e",
   "metadata": {
    "id": "d92c843e"
   },
   "source": [
    "__Your Answers Here:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5643c9e",
   "metadata": {
    "id": "f5643c9e"
   },
   "source": [
    "Give an example of how you could run the flu vaccine that is double-blind?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5759900",
   "metadata": {
    "id": "f5759900"
   },
   "source": [
    "__Your Answers Here:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51e82c",
   "metadata": {
    "id": "ad51e82c"
   },
   "source": [
    "## Types of Variables: level of measurement\n",
    "\n",
    "Let's recall the variable types. The variables can be numerical or categorical.\n",
    "\n",
    "Numerical variables can take any value. They split to:\n",
    "    \n",
    "* **Interval**: numerical values measured along the scale, where all points are equidistant.\n",
    "“+” and “-” operations are meaningful, but “ ·” and “÷” are not\n",
    "E.g. year, credit score, temperature in Celsius\n",
    "\n",
    "* **Ratio**: interval variables with a clear definition of 0. Absolute zero exists and has a meaning.\n",
    "“+”,  “-”, “ ·”  and “÷” are meaningful operations\n",
    "E.g. age, income, temperature in Kelvin\n",
    "\n",
    "\n",
    "Categorical variables take discrete values. They split to:\n",
    "* **Nominal**: two or more categories, without an order\n",
    "E.g. nationality, language, colour\n",
    "* **Ordinal**: two or more categories, with an order or ranking\n",
    "E.g. finishing place in a race (1st, 2nd); company size (1-50, 51-200 employees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885eeb14",
   "metadata": {
    "id": "885eeb14"
   },
   "source": [
    "# Bootstrapping\n",
    "\n",
    "Bootstrapping and permutation are two resampling methods.\n",
    "\n",
    "The basic idea behind bootstrapping comes from the issues associated with repeated sampling from a population. For a data scientist, it is often desired to do so. However, it may be impractical, expensive or not possible (sample items destroyed during sampling).\n",
    "\n",
    "Thus if we cannot resample from the population (the true sampling distribution is unavailable), **we resample from the best approximation of the population we have - which is the sample itself (producing a bootstrap distribution).**\n",
    "\n",
    "Bootstrapping allows you to estimate the distribution of almost any statistic using random sampling methods. We can use it to estimate confidence intervals around point estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf566f90",
   "metadata": {
    "id": "bf566f90"
   },
   "source": [
    "### Bootstrapping Approach\n",
    "\n",
    "To understand how process of resampling from the sample itself works, we will cover it in a step-by-step approach.\n",
    "\n",
    "  1. Use the original sample to represent the population.\n",
    "  2. Take repeated samples from the orginal sample (sample of sample is called re-sample).\n",
    "  3. Use these re-samples to calculate an estimate for the population statistic (mean or median)\n",
    "  4. Gather all calculated values to  produce a distribution of estimates (e.g. distribution of means or medians)\n",
    "  \n",
    "    → by taking 0.025 and 0.0975 quantiles of the resampling distribution we can find a 95% confidence interval for the original population estimate.\n",
    "\n",
    "**Bootstrapping can be used with any estimate: mean, variance, skewness etc.**\n",
    "\n",
    "![](https://i.imgur.com/TWh7y0z.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cf23b",
   "metadata": {
    "id": "8a5cf23b"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Bootstrapping:\n",
    "  - Take the sample: 8, 12, 58, 94, 103, 115, drawn from a population with unknown distribution\n",
    "  - Re-sample with replacement 10000 times with sample(x, size, replace=TRUE).\n",
    "  - Compute a vector with the means for each re-sample.\n",
    "  - Plot their sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53236210",
   "metadata": {
    "id": "53236210"
   },
   "outputs": [],
   "source": [
    "#your code here:\n",
    "\n",
    "sample = [8, 12, 58, 94, 103, 115]\n",
    "\n",
    "sample_means = []\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4fdaf",
   "metadata": {
    "id": "dda4fdaf"
   },
   "source": [
    "### Bonus Exercise\n",
    "\n",
    "The next step in this bootstrapping approach would be to calculate a 95% confidence interval for the mean of this population - you will learn how to calculate confidence intervals in the bootcamp.\n",
    "\n",
    "However, if you are familiar with calculating confidence intervals already, please complete the final (bonus) part of this exercise by:\n",
    "  - Calculating a 95% confidence interval for the mean of this population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d737117",
   "metadata": {
    "id": "0d737117"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b0e36",
   "metadata": {
    "id": "846b0e36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46f0e2a",
   "metadata": {
    "id": "f46f0e2a"
   },
   "source": [
    "# Permutation Tests\n",
    "\n",
    "In addition to bootstrapping, another resampling method is permutation tests.\n",
    "\n",
    "This is another way of making decisions about whether the differences we observe arose due to randomness or due to our treatment conditions.\n",
    "\n",
    "If the treatment had no effect, then observations should randomly fall into the two groups, and any of these rearrangements (permutations) would be equally likely.\n",
    "\n",
    "Like bootstrapping, we don’t need to worry about assumptions or what distribution our data follow.\n",
    "\n",
    "We only rely on the possible rearrangements of these observations into the two groups.\n",
    "\n",
    "For hypothesis testing:\n",
    "\n",
    "  - $H_0$: The observations are exchangeable across groups\n",
    "\n",
    "  - $H_1$: The observations are not exchangeable across groups (the current arrangement into groups was not due to chance)\n",
    "\n",
    "\n",
    "\n",
    "For a visual explanation of the intuition behind permutation testing, please **take a look at this helpful [link](https://www.jwilber.me/permutationtest/).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e2719",
   "metadata": {
    "id": "738e2719"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Run the code given below to create a sample dataset for an experiment on plant growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ae215",
   "metadata": {
    "id": "d80ae215"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = range(30)\n",
    "weight = [4.17, 5.58, 5.18, 6.11, 4.50, 4.61, 5.17, 4.53, 5.33, \n",
    "          5.14, 4.81, 4.17, 4.41, 3.59, 5.87, 3.83, 6.03, 4.89, \n",
    "          4.32, 4.69, 6.31, 5.12, 5.54, 5.50, 5.37, 5.29, 4.92, \n",
    "          6.15, 5.80, 5.26]\n",
    "groups = list(np.repeat(['ctrl'], 10)) + list(np.repeat(['trt1'], 10)) + list(np.repeat(['trt2'], 10))\n",
    "\n",
    "plant_growth = pd.DataFrame({\n",
    "    'X': x,\n",
    "    'weight': weight,\n",
    "    'groups': groups\n",
    "})\n",
    "\n",
    "plant_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f895d81",
   "metadata": {
    "id": "2f895d81"
   },
   "source": [
    "You would like to run a permutation test to decide if the treatment2 had an effect.\n",
    "In other words, is this grouping of observations into treatment and control groups likely to have happened randomly?\n",
    "\n",
    "To do so, you begin by:\n",
    "\n",
    "- Getting all possible rearrangements of these observations into the two groups\n",
    "- For each rearrangement (permutation), calculate the difference in group means\n",
    "- Compare the difference we observed to the distribution of possible differences in all permutations (histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbf93f",
   "metadata": {
    "id": "d2fbf93f"
   },
   "outputs": [],
   "source": [
    "# Permutation test for difference between two groups\n",
    "from itertools import combinations\n",
    "\n",
    "# our data\n",
    "x = plant_growth[plant_growth.groups==\"ctrl\"]['weight']\n",
    "y = plant_growth[plant_growth.groups==\"trt2\"]['weight']\n",
    "\n",
    "n = len(x) + len(y)\n",
    "\n",
    "# 1) get all the possible combinations of 10 observations\n",
    "# using combination instead of permutation because we\n",
    "# don't care about the order of all 10 obs, just whether\n",
    "# they are in group 1 or group 2\n",
    "perm_control = list(combinations(x.tolist() + y.tolist(), n//2))\n",
    "perm_control = np.array(perm_control)\n",
    "\n",
    "# trick to get the corresponding observations for treatment group\n",
    "perm_training = np.flip(perm_control, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe3967",
   "metadata": {
    "id": "5bbe3967"
   },
   "outputs": [],
   "source": [
    "# For each rearrangement (permutation), calculate the difference in group means.\n",
    "mean_diff_actual = np.mean(perm_control, axis=1) - np.mean(perm_training, axis=1)\n",
    "mean_diff_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d6582",
   "metadata": {
    "id": "2f4d6582"
   },
   "outputs": [],
   "source": [
    "mean_diff_obs = np.mean(x) - np.mean(y)\n",
    "mean_diff_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c42aa7",
   "metadata": {
    "id": "51c42aa7"
   },
   "outputs": [],
   "source": [
    "sns.histplot(mean_diff_actual, bins=30)\n",
    "plt.axvline(mean_diff_obs, color='red', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425290e",
   "metadata": {
    "id": "e425290e"
   },
   "source": [
    "### Bonus Exercise\n",
    "\n",
    "We will not cover the next steps needed to complete the permutation tests now - you will learn about them in the bootcamp.\n",
    "\n",
    "\n",
    "However, if you are familiar with confidence intervals and p-values already, please complete the permutation test exercise by:\n",
    "\n",
    "- See what range 99% of these group means fall into.\n",
    "- See if the difference in means we observe in the data falls within this 99% range.\n",
    "- Alternatively, to get a p-value, see what the probability of observing a difference of the same or larger magnitude than what we saw in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea99ac",
   "metadata": {
    "id": "8aea99ac"
   },
   "outputs": [],
   "source": [
    "### Bonus\n",
    "## rest of this exercise, save for in-class\n",
    "# get critical values for a 2-sided test\n",
    "# that is, which values are the interval that contains\n",
    "# 95% of permutation mean differences?\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debfb23",
   "metadata": {
    "id": "6debfb23"
   },
   "outputs": [],
   "source": [
    "# plot the interval and the difference in means that\n",
    "# we observed\n",
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af345846",
   "metadata": {
    "id": "af345846"
   },
   "outputs": [],
   "source": [
    "# how many permutations had a mean diff equal to\n",
    "# or greater than the one we observed?\n",
    "\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "\n",
    "# dividing this by the total number of permutations\n",
    "# tells us how likely it was that our observation arose by chance\n",
    "# (if we drew a permutation at random) - our p-value\n",
    "\n",
    "<YOUR CODE HERE>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of pw_stats_03_inferential_statistics.ipynb",
   "provenance": [
    {
     "file_id": "1qFdkbSRHGzmPyHUaFSltroaQZo6O6beF",
     "timestamp": 1630679117413
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
